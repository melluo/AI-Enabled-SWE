{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6 - Lab 2: Creating a Conversational Multi-Agent System (Solution)\n",
    "\n",
    "**Objective:** Integrate the multi-agent LangGraph system from the previous lab into the FastAPI backend, creating a new `/chat` endpoint that is stateful and can handle conversational memory.\n",
    "\n",
    "**Introduction:**\n",
    "This solution notebook provides the complete code for deploying the LangGraph agent as a conversational API. It covers creating a stateless endpoint, building a Streamlit UI, and finally implementing stateful memory management.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "**Explanation:**\n",
    "This setup code mocks the necessary components for the lab. We create a mock `multi_agent_app` to simulate the compiled LangGraph from Lab 6.1. This allows us to develop the API and UI without needing to run the full, complex graph. In a real application, you would import your compiled graph object here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import save_artifact\n",
    "print(\"Setup complete. The following cells contain the code for your '.py' files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges - Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 & 3: FastAPI Backend (`app/main.py`)\n",
    "\n",
    "**Explanation:**\n",
    "This code block contains the complete, final version of the backend code to be added to `app/main.py`. It includes both the stateless and stateful endpoints for comparison.\n",
    "\n",
    "1.  **`StatefulChatRequest`**: The request model is updated to include an optional `session_id`.\n",
    "2.  **Endpoint Logic**: The stateful endpoint checks if a `session_id` was provided. If not, it creates a new one, establishing a new conversation session.\n",
    "3.  **`config` object**: This is the most critical part. We pass a `config` dictionary to the `.invoke()` method. LangGraph specifically looks for the `{\"configurable\": {\"session_id\": \"...\"}}` structure to manage memory. When it sees this, it automatically retrieves the history for that session, includes it in the context for the LLM, and saves the new turn to that same history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_backend_code = \"\"\"# In app/main.py, add the following...\n",
    "import uuid\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# This would be your actual compiled LangGraph application\n",
    "# from your_rag_system import multi_agent_app \n",
    "class MockLangGraphApp:\n",
    "    def invoke(self, inputs, config):\n",
    "        session_id = config.get('configurable', {}).get('session_id', 'N/A')\n",
    "        print(f\"Invoking agent for session {session_id} with question: {inputs.get('question')}\")\n",
    "        return {\"answer\": f\"This is a stateful answer to: '{inputs.get('question')}'\"}\n",
    "multi_agent_app = MockLangGraphApp()\n",
    "\n",
    "# --- Challenge 1: Stateless Endpoint ---\n",
    "class ChatRequest(BaseModel):\n",
    "    question: str\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "def chat_endpoint(request: ChatRequest):\n",
    "    # Note the empty config dictionary, indicating a stateless call\n",
    "    result = multi_agent_app.invoke({\"question\": request.question}, config={})\n",
    "    return {\"answer\": result.get(\"answer\")}\n",
    "\n",
    "# --- Challenge 3: Stateful Endpoint ---\n",
    "class StatefulChatRequest(BaseModel):\n",
    "    question: str\n",
    "    session_id: str | None = None\n",
    "\n",
    "@app.post(\"/stateful_chat\")\n",
    "def stateful_chat_endpoint(request: StatefulChatRequest):\n",
    "    session_id = request.session_id if request.session_id else str(uuid.uuid4())\n",
    "    \n",
    "    # LangGraph uses this specific config structure to manage conversational memory\n",
    "    config = {\"configurable\": {\"session_id\": session_id}}\n",
    "    \n",
    "    inputs = {\"question\": request.question}\n",
    "    result = multi_agent_app.invoke(inputs, config=config)\n",
    "    \n",
    "    return {\n",
    "        \"answer\": result.get(\"answer\"),\n",
    "        \"session_id\": session_id\n",
    "    }\n",
    "\"\"\"\n",
    "print(\"--- Code to add to app/main.py ---\")\n",
    "print(final_backend_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 & 3: Streamlit UI (`chat_ui.py`)\n",
    "\n",
    "**Explanation:**\n",
    "This script creates the web UI for our chatbot. \n",
    "-   **`st.session_state`**: This is Streamlit's built-in dictionary for maintaining state across user interactions. We use it to store the chat history and the current `session_id`.\n",
    "-   **Stateful Logic**: When the user sends a message, the app makes a POST request to our `/stateful_chat` endpoint. It includes the current `session_id` from `st.session_state`. When it gets a response, it updates the history and, crucially, saves the `session_id` from the response back into `st.session_state` for the next turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateful_chat_ui_code = \"\"\"import streamlit as st\n",
    "import requests\n",
    "\n",
    "st.title(\"STATEFUL Multi-Agent RAG Chatbot\")\n",
    "\n",
    "# Initialize session state variables\n",
    "if 'history' not in st.session_state:\n",
    "    st.session_state.history = []\n",
    "if 'session_id' not in st.session_state:\n",
    "    st.session_state.session_id = None\n",
    "\n",
    "question = st.text_input(\"Ask a question about your project:\", key=\"input_stateful\")\n",
    "\n",
    "if st.button(\"Send Request\"):\n",
    "    if question:\n",
    "        # The payload now includes the session_id from our state\n",
    "        payload = {\"question\": question, \"session_id\": st.session_state.session_id}\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\"http://127.0.0.1:8000/stateful_chat\", json=payload)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                # Store the session ID from the response for the next turn\n",
    "                st.session_state.session_id = data.get('session_id') \n",
    "                answer = data.get('answer')\n",
    "                st.session_state.history.append((\"You\", question))\n",
    "                st.session_state.history.append((\"Agent\", answer))\n",
    "            else:\n",
    "                st.error(f\"Failed to get response from API. Status: {response.status_code}\")\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            st.error(f\"Could not connect to the API. Is your FastAPI server running? Error: {e}\")\n",
    "\n",
    "# Display the chat history\n",
    "for author, text in st.session_state.history:\n",
    "    st.write(f\"**{author}:** {text}\")\n",
    "\n",
    "st.sidebar.title(\"Session Info\")\n",
    "st.sidebar.write(f\"Current Session ID: {st.session_state.session_id}\")\n",
    "\"\"\"\n",
    "save_artifact(stateful_chat_ui_code, \"chat_ui.py\")\n",
    "print(\"Saved 'chat_ui.py'. To run it, open your terminal and execute: streamlit run chat_ui.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent! You have successfully integrated your powerful multi-agent system into a real-world application. You created a stateless API endpoint, built a UI for it, and then performed the critical upgrade to make it a stateful, conversational agent with memory. This is the complete pattern for deploying sophisticated AI assistants that can engage in natural, multi-turn dialogues with users.\n",
    "\n",
    "> **Key Takeaway:** Stateful conversation is achieved by passing a consistent `session_id` to your agent. Frameworks like LangGraph use this ID to automatically manage and retrieve the history for each user, enabling context-aware, multi-turn conversations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}