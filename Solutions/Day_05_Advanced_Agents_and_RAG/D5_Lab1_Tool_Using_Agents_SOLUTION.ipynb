{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5 - Lab 1: Tool-Using Agents (Solution)\n",
    "\n",
    "**Objective:** Build agents that can use external tools to accomplish tasks they cannot perform on their own, using both LangChain and custom Python functions.\n",
    "\n",
    "**Introduction:**\n",
    "This solution notebook provides the complete code and explanations for building your first agents. It dives into the LangChain framework for control and flexibility, culminating in a multi-tool agent.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "**Explanation:**\n",
    "We ensure all necessary libraries for this lab are installed. `langchain` and its related packages provide the core framework for building agents, while `tavily-python` is the SDK for the Tavily Search API, which our agent will use as a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# This helper will install packages if they are not found\n",
    "import importlib\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "    except ImportError:\n",
    "        print(f\"{package} not found, installing...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "install_if_missing('langchain')\n",
    "install_if_missing('langchain_community')\n",
    "install_if_missing('langchain_openai')\n",
    "install_if_missing('tavily')\n",
    "\n",
    "from utils import setup_llm_client\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges - Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Building a LangChain Agent with One Tool\n",
    "\n",
    "**Explanation:**\n",
    "LangChain provides a modular and flexible way to build agents. \n",
    "1.  **Tool:** We instantiate `TavilySearchResults`, which is a pre-built LangChain component that knows how to call the Tavily API.\n",
    "2.  **Prompt:** The prompt is crucial. `ChatPromptTemplate.from_messages` creates a template for the conversation. The key part is the `(\"placeholder\", \"{agent_scratchpad}\")`. The `agent_scratchpad` is a special variable where the agent's internal monologue (its thoughts, tool calls, and tool outputs) is stored. This allows the agent to reason about its actions.\n",
    "3.  **Agent:** `create_tool_calling_agent` binds the LLM, the tools, and the prompt together into a runnable agent.\n",
    "4.  **AgentExecutor:** This is the runtime for the agent. It takes the agent and the tools and handles the logic of calling the agent, parsing its output to see if it wants to use a tool, executing the tool, and passing the result back to the agent to continue its reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# We need to use a LangChain LLM wrapper\n",
    "llm = ChatOpenAI(model=model_name)\n",
    "\n",
    "# 1. Instantiate the Tavily search tool\n",
    "search_tool = TavilySearchResults(max_results=2)\n",
    "tools = [search_tool]\n",
    "\n",
    "# 2. Create the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "# 3. Create the agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# 4. Create the AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# 5. Invoke the agent with a question\n",
    "question = \"What was the score of the last Super Bowl?\"\n",
    "result = agent_executor.invoke({\"input\": question})\n",
    "\n",
    "print(f\"\\nFinal Answer: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Building a Multi-Tool Agent\n",
    "\n",
    "**Explanation:**\n",
    "This challenge demonstrates the core reasoning power of an agent. \n",
    "1.  **`@tool` Decorator:** LangChain provides a simple `@tool` decorator to turn any Python function into a tool that an agent can use. The function's docstring is very important, as the agent uses it to understand what the tool does.\n",
    "2.  **Tool List:** We create a new list containing both our custom `multiply` tool and the pre-built `TavilySearchResults` tool.\n",
    "3.  **Reasoning:** When the agent receives a query, it looks at the user's question and the docstrings of all available tools. It then makes a decision about which tool, if any, is the most appropriate for the task. This ability to choose the right tool for the job is the fundamental capability of an agent. For \"25 * 48\", it will see the \"Multiplies two integers\" docstring and choose the `multiply` tool. For \"Who is the CEO of Apple?\", it will recognize that it needs external information and choose the search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# 1. Define your custom calculator tool\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies two integers together.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# 2. Create the new list of tools\n",
    "multi_tool_list = [TavilySearchResults(max_results=2), multiply]\n",
    "\n",
    "# 3. Create the new multi-tool agent and executor\n",
    "multi_tool_agent = create_tool_calling_agent(llm, multi_tool_list, prompt)\n",
    "multi_tool_executor = AgentExecutor(agent=multi_tool_agent, tools=multi_tool_list, verbose=True)\n",
    "\n",
    "# 4. Invoke the agent with a math question\n",
    "math_question = \"What is 25 * 48?\"\n",
    "math_result = multi_tool_executor.invoke({\"input\": math_question})\n",
    "print(f\"\\nQuery: {math_question}\\nFinal Answer: {math_result['output']}\\n\")\n",
    "\n",
    "# 5. Invoke the agent with a search question\n",
    "search_question = \"Who is the current CEO of Apple?\"\n",
    "search_result = multi_tool_executor.invoke({\"input\": search_question})\n",
    "print(f\"\\nQuery: {search_question}\\nFinal Answer: {search_result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Improving Tool Selection with Better Docstrings\n",
    "\n",
    "**Explanation:**\n",
    "This challenge highlights the importance of 'prompt engineering' your tool's docstrings. The agent's reasoning process is heavily influenced by the descriptions of the tools it has available. A vague docstring might lead the agent to ignore a tool or use it incorrectly. A highly descriptive docstring, as shown in the solution, gives the agent a much clearer signal about the tool's purpose, leading to more reliable and efficient tool selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Redefine your custom tool with a more descriptive docstring.\n",
    "@tool\n",
    "def better_multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Use this tool for mathematical calculations involving multiplication. It takes two integers as input and returns their product.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# 2. Re-create the tool list, agent, and executor with the improved tool.\n",
    "improved_tool_list = [TavilySearchResults(max_results=2), better_multiply]\n",
    "improved_agent = create_tool_calling_agent(llm, improved_tool_list, prompt)\n",
    "improved_executor = AgentExecutor(agent=improved_agent, tools=improved_tool_list, verbose=True)\n",
    "\n",
    "# 3. Invoke the agent again.\n",
    "math_question = \"What is 25 * 48?\"\n",
    "improved_math_result = improved_executor.invoke({\"input\": math_question})\n",
    "print(f\"\\nQuery: {math_question}\\nFinal Answer: {improved_math_result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Congratulations! You have successfully built your first AI agents. You've learned how to give agents tools to extend their capabilities and, most importantly, how to build an agent that can reason about which tool to use for a specific task. This is the foundational skill for all advanced agentic workflows we will explore in the coming days.\n",
    "\n",
    "> **Key Takeaway:** An agent's ability to reason and act depends on its understanding of its tools. The most critical part of creating a custom tool is writing a clear, descriptive docstring that tells the agent exactly what the tool does and when to use it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}