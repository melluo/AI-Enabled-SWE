{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5 - Lab 2: Plan-and-Execute & Multi-Agent Systems (Solution)\n",
    "\n",
    "**Objective:** Explore advanced agent architectures, including the plan-and-execute model and conversational multi-agent systems using Microsoft's AutoGen.\n",
    "\n",
    "**Introduction:**\n",
    "This solution notebook provides the complete code and explanations for Lab 5.2. It covers the plan-and-execute pattern and demonstrates how to build and manage a team of collaborative AI agents with AutoGen.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# This helper will install packages if they are not found\n",
    "import importlib\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "    except ImportError:\n",
    "        print(f\"{package} not found, installing...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "install_if_missing('pyautogen')\n",
    "\n",
    "from utils import setup_llm_client, get_completion\n",
    "import autogen\n",
    "\n",
    "# We will use the OpenAI provider for this lab as AutoGen is optimized for it.\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges - Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): A Plan-and-Execute Agent\n",
    "\n",
    "**Explanation:**\n",
    "This pattern separates the creative, high-level thinking from the detailed, low-level implementation. \n",
    "1.  **Planner Agent:** The first prompt asks the LLM to act as an architect. Its only job is to think and create a detailed plan or specification. This focuses the LLM's attention on getting the logic and structure right without worrying about code syntax.\n",
    "2.  **Coder Agent:** The second prompt is highly constrained. It receives the detailed spec from the planner and is instructed to *only* write the code that implements that spec. By giving it a clear plan to follow, we reduce the chances of the LLM misunderstanding the requirements or generating incorrect code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_level_goal = \"Create a Python function that takes a list of strings and returns a new list containing only the strings that are palindromes.\"\n",
    "\n",
    "# 1. Write the prompt for the Planner Agent.\n",
    "planner_prompt = f\"\"\"\n",
    "You are a senior software architect. Your task is to create a detailed specification for a Python function based on the following goal.\n",
    "\n",
    "**Goal:** {high_level_goal}\n",
    "\n",
    "Provide a specification that includes:\n",
    "- The function signature with type hints.\n",
    "- A clear description of what the function does.\n",
    "- A step-by-step description of the implementation logic.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Planner Agent Generating Spec ---\")\n",
    "function_spec = get_completion(planner_prompt, client, model_name, api_provider)\n",
    "print(function_spec)\n",
    "\n",
    "# 2. Write the prompt for the Coder Agent.\n",
    "coder_prompt = f\"\"\"\n",
    "You are a Python developer. Your task is to write the code for a function based ONLY on the following specification.\n",
    "\n",
    "**Specification:**\n",
    "<spec>\n",
    "{function_spec}\n",
    "</spec>\n",
    "\n",
    "Only output the raw Python code for the function. Do not include any explanation or example usage.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Coder Agent Generating Code ---\")\n",
    "generated_function = get_completion(coder_prompt, client, model_name, api_provider)\n",
    "print(generated_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): A Three-Agent AutoGen Team\n",
    "\n",
    "**Explanation:**\n",
    "AutoGen allows us to create multiple, specialized agents that collaborate through conversation.\n",
    "1.  **`config_list`**: This tells AutoGen how to configure the LLM client. It's how we provide the model name and API key.\n",
    "2.  **`UserProxyAgent`**: This special agent acts as the proxy for the human user. We set `human_input_mode` to `TERMINATE` to tell it that once a solution is found (i.e., the code is written), the conversation should end automatically without asking for human feedback.\n",
    "3.  **`AssistantAgent`**: These are the general-purpose AI agents. We create two of them, giving each a unique `name` and a `system_message` that defines its role and personality.\n",
    "4.  **`GroupChat`**: This object manages the conversation between the list of agents.\n",
    "5.  **`GroupChatManager`**: This is an agent that orchestrates the group chat, deciding which agent should speak next.\n",
    "6.  **`user_proxy.initiate_chat`**: This kicks off the conversation with an initial message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the config_list for the LLM.\n",
    "config_list = [\n",
    "    {\n",
    "        'model': model_name,\n",
    "        'api_key': os.getenv(\"OPENAI_API_KEY\"),\n",
    "    }\n",
    "]\n",
    "\n",
    "# 2. Create the UserProxyAgent.\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"UserProxy\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False} # Specify a directory for generated code\n",
    ")\n",
    "\n",
    "# 3. Create the ProductManager agent.\n",
    "product_manager = autogen.AssistantAgent(\n",
    "    name=\"ProductManager\",\n",
    "    system_message=\"You are a Product Manager. Your job is to clarify requirements and create a clear, actionable plan for the developer.\",\n",
    "    llm_config={\"config_list\": config_list}\n",
    ")\n",
    "\n",
    "# 4. Create the Developer agent.\n",
    "developer = autogen.AssistantAgent(\n",
    "    name=\"Developer\",\n",
    "    system_message=\"You are a senior Python developer. You write clean, efficient Python code based on the Product Manager's plan. You must include the code in a ```python block.\",\n",
    "    llm_config={\"config_list\": config_list}\n",
    ")\n",
    "\n",
    "# 5. Create the GroupChat and GroupChatManager.\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, product_manager, developer], messages=[], max_round=12)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config={\"config_list\": config_list})\n",
    "\n",
    "# 6. Initiate the chat with a feature request.\n",
    "feature_request = \"Add a feature to our API to calculate the complexity of a password based on length, and the presence of uppercase, lowercase, numbers, and symbols.\"\n",
    "user_proxy.initiate_chat(manager, message=feature_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Multi-Agent System with a Code Reviewer\n",
    "\n",
    "**Explanation:**\n",
    "This challenge makes our agent team more realistic by adding a QA step. The `is_termination_msg` function is the key to creating complex, multi-step workflows. By defining a custom condition for ending the conversation (e.g., waiting for the word 'APPROVED'), we can orchestrate sophisticated loops of interaction, like a developer submitting code and a reviewer providing feedback until the quality bar is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the CodeReviewer agent.\n",
    "code_reviewer = autogen.AssistantAgent(\n",
    "    name=\"CodeReviewer\",\n",
    "    system_message=\"You are a Code Reviewer. Your job is to inspect Python code for quality, correctness, and best practices. You must point out any issues. If the code is perfect, you must respond with only the word 'APPROVED'.\",\n",
    "    llm_config={\"config_list\": config_list}\n",
    ")\n",
    "\n",
    "# 2. Create a new UserProxyAgent with a custom termination message check.\n",
    "user_proxy_with_review = autogen.UserProxyAgent(\n",
    "    name=\"UserProxyWithReview\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    # This lambda function checks if the last message contains 'APPROVED'\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"APPROVED\")\n",
    ")\n",
    "\n",
    "# 3. Create the new 4-agent GroupChat and Manager.\n",
    "four_agent_groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy_with_review, product_manager, developer, code_reviewer], \n",
    "    messages=[], \n",
    "    max_round=15\n",
    ")\n",
    "four_agent_manager = autogen.GroupChatManager(groupchat=four_agent_groupchat, llm_config={\"config_list\": config_list})\n",
    "\n",
    "# 4. Initiate the chat.\n",
    "user_proxy_with_review.initiate_chat(four_agent_manager, message=feature_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent work! You have now explored two powerful advanced agentic architectures. You learned how the plan-and-execute model can lead to more structured and reliable code generation, and you used AutoGen to simulate a collaborative team of AI agents that can plan, code, and review work. These foundational patterns are the building blocks for creating highly sophisticated and autonomous AI systems.\n",
    "\n",
    "> **Key Takeaway:** Multi-agent systems allow you to break down a complex problem into smaller, more manageable tasks, each handled by a specialized AI agent. This division of labor, whether in a sequential 'plan-and-execute' pattern or a collaborative conversation, often leads to higher quality and more reliable results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}