{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 6 - Lab 2: Creating a Conversational Multi-Agent System (Solution)\n",
        "\n",
        "**Objective:** Integrate the multi-agent LangGraph system from the previous lab into the FastAPI backend, creating a new `/chat` endpoint that is stateful and can handle conversational memory.\n",
        "\n",
        "**Introduction:**\n",
        "This solution notebook provides the complete code for deploying the LangGraph agent as a conversational API. It covers creating a stateless endpoint, building a Streamlit UI, and finally implementing stateful memory management."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup\n",
        "\n",
        "**Explanation:**\n",
        "This setup code mocks the necessary components for the lab. We create a mock `multi_agent_app` to simulate the compiled LangGraph from Lab 6.1. This allows us to develop the API and UI without needing to run the full, complex graph. We also initialize an in-memory dictionary, `conversation_histories`, which will serve as our simple session store for the advanced challenge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the project's root directory to the Python path\n",
        "try:\n",
        "    # This works when running as a script\n",
        "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))\n",
        "except NameError:\n",
        "    # This works when running in an interactive environment (like a notebook)\n",
        "    # We go up two levels from the notebook's directory to the project root.\n",
        "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import uuid\n",
        "import streamlit as st\n",
        "import requests\n",
        "from utils import save_artifact\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class MockLangGraphApp:\n",
        "    def invoke(self, inputs, config):\n",
        "        session_id = config.get('configurable', {}).get('session_id', 'N/A')\n",
        "        print(f\"Invoking agent for session {session_id}\")\n",
        "        question = inputs.get('question')\n",
        "        # In a real app, LangGraph's memory would use the session_id to get history\n",
        "        return {\"final_answer\": f\"This is a stateful answer to: '{question}'\"}\n",
        "\n",
        "multi_agent_app = MockLangGraphApp()\n",
        "\n",
        "# In-memory store for conversation histories (for demonstration)\n",
        "conversation_histories = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: The Challenges - Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 1 (Foundational): Creating a Stateless Chat Endpoint\n",
        "\n",
        "**Explanation:**\n",
        "This is the most basic form of an API endpoint. It defines a `ChatRequest` model to validate the incoming data, accepts a `POST` request, and simply invokes the agent with the question. It has no concept of memory; every call is treated as a brand new conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ChatRequest(BaseModel):\n",
        "    question: str\n",
        "\n",
        "@app.post(\"/chat\")\n",
        "def chat_endpoint(request: ChatRequest):\n",
        "    # Note the empty config dictionary, indicating a stateless call\n",
        "    result = multi_agent_app.invoke({\"question\": request.question}, config={})\n",
        "    return {\"answer\": result.get(\"final_answer\")}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 2 (Intermediate): Building a Simple Streamlit UI\n",
        "\n",
        "**Explanation:**\n",
        "This script creates a simple web UI. Streamlit's `st.session_state` is used to maintain state across user interactions within the app, allowing us to build up a chat history for display. When the user clicks the button, it uses the popular `requests` library to send the question to our running FastAPI backend and displays the JSON response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_ui_code = \"\"\"\n",
        "import streamlit as st\n",
        "import requests\n",
        "\n",
        "st.title(\"Multi-Agent RAG Chatbot\")\n",
        "\n",
        "if 'history' not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "\n",
        "question = st.text_input(\"Ask a question about the project:\", key=\"input\")\n",
        "\n",
        "if st.button(\"Send\"):\n",
        "    if question:\n",
        "        # For this intermediate step, we call the stateless endpoint\n",
        "        response = requests.post(\"http://127.0.0.1:8000/chat\", json={\"question\": question})\n",
        "        if response.status_code == 200:\n",
        "            answer = response.json().get('answer')\n",
        "            st.session_state.history.append((\"You\", question))\n",
        "            st.session_state.history.append((\"Agent\", answer))\n",
        "        else:\n",
        "            st.error(\"Failed to get response from API.\")\n",
        "\n",
        "for author, text in st.session_state.history:\n",
        "    st.write(f\"**{author}:** {text}\")\n",
        "\"\"\"\n",
        "save_artifact(chat_ui_code, \"labs/Day_06_RAG_Agents/chat_ui.py\")\n",
        "print(\"Saved 'chat_ui.py'. To run it, open your terminal and execute: streamlit run labs/Day_06_RAG_Agents/chat_ui.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 3 (Advanced): Implementing Conversational Memory\n",
        "\n",
        "**Explanation:**\n",
        "This is the complete, stateful solution. \n",
        "1.  **`StatefulChatRequest`**: The request model now includes an optional `session_id`.\n",
        "2.  **Endpoint Logic**: The endpoint checks if a `session_id` was provided. If not, it creates a new one, establishing a new conversation session.\n",
        "3.  **`config` object**: This is the most critical part. We pass a `config` dictionary to the `.invoke()` method. LangGraph specifically looks for the `{\"configurable\": {\"session_id\": \"...\"}}` structure to manage memory. When it sees this, it automatically retrieves the history for that session, includes it in the context for the LLM, and saves the new turn to that same history.\n",
        "4.  **UI Update**: The Streamlit UI must be updated to store the `session_id` it receives from the first response and send it back on all subsequent requests, maintaining the conversational context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StatefulChatRequest(BaseModel):\n",
        "    question: str\n",
        "    session_id: str | None = None\n",
        "\n",
        "@app.post(\"/stateful_chat\")\n",
        "def stateful_chat_endpoint(request: StatefulChatRequest):\n",
        "    session_id = request.session_id if request.session_id else str(uuid.uuid4())\n",
        "    \n",
        "    # In a real app with LangGraph's built-in memory, you just need to pass the session_id in the config.\n",
        "    # LangGraph handles the retrieval and saving of history for you.\n",
        "    config = {\"configurable\": {\"session_id\": session_id}}\n",
        "    \n",
        "    inputs = {\"question\": request.question}\n",
        "    result = multi_agent_app.invoke(inputs, config=config)\n",
        "    \n",
        "    return {\n",
        "        \"answer\": result.get(\"final_answer\"),\n",
        "        \"session_id\": session_id\n",
        "    }\n",
        "\n",
        "stateful_chat_ui_code = \"\"\"\n",
        "import streamlit as st\n",
        "import requests\n",
        "\n",
        "st.title(\"STATEFUL Multi-Agent RAG Chatbot\")\n",
        "\n",
        "if 'history' not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "if 'session_id' not in st.session_state:\n",
        "    st.session_state.session_id = None\n",
        "\n",
        "question = st.text_input(\"Ask a follow-up question:\", key=\"input_stateful\")\n",
        "\n",
        "if st.button(\"Send Stateful Request\"):\n",
        "    if question:\n",
        "        payload = {\"question\": question, \"session_id\": st.session_state.session_id}\n",
        "        response = requests.post(\"http://127.0.0.1:8000/stateful_chat\", json=payload)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            st.session_state.session_id = data.get('session_id') # Store the session ID\n",
        "            answer = data.get('answer')\n",
        "            st.session_state.history.append((\"You\", question))\n",
        "            st.session_state.history.append((\"Agent\", answer))\n",
        "        else:\n",
        "            st.error(\"Failed to get response from API.\")\n",
        "\n",
        "for author, text in st.session_state.history:\n",
        "    st.write(f\"**{author}:** {text}\")\n",
        "st.write(f\"Current Session ID: {st.session_state.session_id}\")\n",
        "\"\"\"\n",
        "save_artifact(stateful_chat_ui_code, \"stateful_chat_ui.py\")\n",
        "print(\"Saved 'stateful_chat_ui.py'. Update your UI code and run it to test the stateful endpoint.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab Conclusion\n",
        "\n",
        "Excellent! You have successfully integrated your powerful multi-agent system into a real-world application. You created a stateless API endpoint, built a UI for it, and then performed the critical upgrade to make it a stateful, conversational agent with memory. This is the complete pattern for deploying sophisticated AI assistants that can engage in natural, multi-turn dialogues with users."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}