{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 1 - Lab 1: AI-Powered Requirements & User Stories (Solution)\n",
        "\n",
        "**Objective:** Use a Large Language Model (LLM) to decompose a vague problem statement into structured features, user personas, and Agile user stories, culminating in a machine-readable JSON artifact.\n",
        "\n",
        "**Introduction:**\n",
        "This notebook contains the complete solution for Lab 1. It demonstrates how to use an LLM to systematically break down a problem, generate structured requirements, and programmatically validate the output. Each step includes explanations of the code and the reasoning behind the prompts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup\n",
        "\n",
        "**Purpose:** This initial block of code prepares our environment for the lab. It imports necessary libraries and configures the connection to the LLM API.\n",
        "\n",
        "**Libraries Explained:**\n",
        "- **`os`**: A standard Python library for interacting with the operating system. We use `os.getenv` to securely read API keys stored in environment variables, which is a best practice to avoid hardcoding secrets in the code.\n",
        "- **`json`**: A standard library for working with JSON data. We use `json.loads` to parse the LLM's text output into a Python dictionary or list, and `json.dumps` to format Python objects into a pretty-printed JSON string for saving.\n",
        "- **`utils`**: A custom helper script provided with this course. \n",
        "  - `setup_llm_client()`: This function handles the logic of reading your `.env` file and initializing the correct API client (e.g., for OpenAI). It centralizes the setup code so we don't have to repeat it in every notebook.\n",
        "  - `get_completion()`: This function takes a prompt and the client information, sends the request to the LLM, and returns the text response. It simplifies the API call process.\n",
        "  - `save_artifact()`: This function takes content and a file path, creates the necessary directories, and saves the content to a file. It ensures our project artifacts are stored consistently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the project's root directory to the Python path\n",
        "try:\n",
        "    # This works when running as a script\n",
        "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))\n",
        "except NameError:\n",
        "    # This works when running in an interactive environment (like a notebook)\n",
        "    # We go up two levels from the notebook's directory to the project root.\n",
        "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from utils import setup_llm_client, get_completion, save_artifact\n",
        "\n",
        "# This function reads your .env file, finds your API key, and sets up the client.\n",
        "# It returns the client object and model information for use in other functions.\n",
        "client, model_name, api_provider = setup_llm_client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: The Problem Statement\n",
        "\n",
        "We define our starting point\u2014a simple, high-level problem statement\u2014as a Python variable. This makes it easy to reuse in multiple prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Define your problem We need a tool to help our company's new hires get up to speed.\n"
          ]
        }
      ],
      "source": [
        "problem_statement = input(\"Define your problem\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: The Challenges\n",
        "\n",
        "Here are the complete solutions for each challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 1 (Foundational): Brainstorming Features\n",
        "\n",
        "**Explanation:**\n",
        "This first challenge is about exploration. We use simple, direct prompts to get the LLM's initial thoughts on the problem. The goal is to generate a broad set of ideas (features and personas) that will serve as the raw material for the more structured tasks to follow. We expect the output to be human-readable markdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Brainstorming Features ---\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "**Error:** An API error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-svcac************************************************************************************************************************************************************tAA.. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Identifying User Personas ---\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "**Error:** An API error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-svcac************************************************************************************************************************************************************tAA.. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# This prompt is direct and open-ended, encouraging the LLM to be creative.\n",
        "features_prompt = f\"\"\"\n",
        "Based on the problem statement: '{problem_statement}', brainstorm a list of potential features for a new hire onboarding tool. \n",
        "Format the output as a simple markdown list.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- Brainstorming Features ---\")\n",
        "brainstormed_features = get_completion(features_prompt, client, model_name, api_provider)\n",
        "\n",
        "# This prompt asks for specific roles to ground the brainstorming in user-centric thinking.\n",
        "personas_prompt = f\"\"\"\n",
        "Based on the problem statement: '{problem_statement}', identify and describe three distinct user personas who would interact with this tool. \n",
        "For each persona, describe their role and main goal.\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n--- Identifying User Personas ---\")\n",
        "user_personas = get_completion(personas_prompt, client, model_name, api_provider)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 2 (Intermediate): Generating Formal User Stories\n",
        "\n",
        "**Explanation:**\n",
        "This challenge represents a significant increase in complexity and value. We are no longer asking for simple text; we are demanding a specific, structured data format (JSON). \n",
        "\n",
        "The prompt is carefully engineered:\n",
        "1.  **Persona:** `You are a Senior Product Manager...` tells the LLM the role it should adopt.\n",
        "2.  **Context:** We provide the previous outputs (`problem_statement`, `brainstormed_features`, `user_personas`) inside `<context>` tags to give the LLM all the necessary information.\n",
        "3.  **Format:** The `OUTPUT REQUIREMENTS` section is extremely explicit. It tells the LLM to *only* output JSON, defines the exact keys for each object, and specifies the format for nested data (like the array of Gherkin strings). This strictness is key to getting reliable, machine-readable output.\n",
        "4.  **Parsing:** The `try...except` block is a crucial step. It attempts to parse the LLM's string output into a Python list of dictionaries. If it succeeds, we know the LLM followed our instructions perfectly. If it fails, we print the raw output to help debug the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The prompt is highly-structured to guide the LLM toward a perfect JSON output.\n",
        "json_user_stories_prompt = f\"\"\"\n",
        "You are a Senior Product Manager creating a product backlog for a new hire onboarding tool.\n",
        "\n",
        "Based on the following context:\n",
        "<context>\n",
        "Problem Statement: {problem_statement}\n",
        "Potential Features: {brainstormed_features}\n",
        "User Personas: {user_personas}\n",
        "</context>\n",
        "\n",
        "Your task is to generate a list of 5 detailed user stories.\n",
        "\n",
        "**OUTPUT REQUIREMENTS**:\n",
        "- You MUST output a valid JSON array. Do not include any text or markdown before or after the JSON array.\n",
        "- Each object in the array must represent a single user story.\n",
        "- Each object must have the following keys: 'id' (an integer), 'persona' (a string from the personas), 'user_story' (a string in the format 'As a [persona], I want [goal], so that [benefit].'), and 'acceptance_criteria' (an array of strings, with each string in Gherkin format 'Given/When/Then').\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- Generating User Stories as JSON ---\")\n",
        "# We set a lower temperature to encourage the LLM to stick to the requested format.\n",
        "json_output_str = get_completion(json_user_stories_prompt, client, model_name, api_provider, temperature=0.2)\n",
        "\n",
        "# Attempt to parse the string output into a Python list.\n",
        "try:\n",
        "    # In some cases, the LLM might wrap the JSON in markdown fences (```json ... ```).\n",
        "    # This line cleans that up before parsing.\n",
        "    if '```' in json_output_str:\n",
        "        json_output_str = json_output_str.split('```')[1].lstrip('json').strip()\n",
        "    \n",
        "    user_stories_json = json.loads(json_output_str)\n",
        "    print(\"Successfully parsed LLM output as JSON.\")\n",
        "    # Pretty-print the first user story to verify its structure\n",
        "    print(\"\\n--- Sample User Story ---\")\n",
        "    print(json.dumps(user_stories_json[0], indent=2))\n",
        "except (json.JSONDecodeError, TypeError, IndexError) as e:\n",
        "    print(f\"Error: Failed to parse LLM output as JSON. Error: {e}\")\n",
        "    print(\"LLM Output was:\\n\", json_output_str)\n",
        "    user_stories_json = [] # Assign an empty list to prevent errors in the next cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 3 (Advanced): Programmatic Validation and Artifact Creation\n",
        "\n",
        "**Explanation:**\n",
        "This is the final and most critical step. We treat the LLM's output as untrusted input and subject it to programmatic validation. This ensures that the artifact we create is reliable and conforms to our project's standards. \n",
        "\n",
        "The `validate_and_save_stories` function acts as a gatekeeper. It checks for the correct data types (a list of objects) and ensures that all required fields are present in each object. Only if all checks pass do we proceed to save the file using `save_artifact`. This creates a trustworthy `user_stories.json` file that can be confidently used as an input for other automated processes in our SDLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_and_save_stories(stories_data):\n",
        "    \"\"\"Validates the structure of the user stories data and saves it if valid.\"\"\"\n",
        "    # Ensure the input is a list and not empty.\n",
        "    if not isinstance(stories_data, list) or not stories_data:\n",
        "        print(\"Validation Failed: Data is not a non-empty list.\")\n",
        "        return\n",
        "\n",
        "    required_keys = ['id', 'persona', 'user_story', 'acceptance_criteria']\n",
        "    is_valid = True\n",
        "\n",
        "    # Iterate through each story object in the list.\n",
        "    for i, story in enumerate(stories_data):\n",
        "        # Check for the presence of all required keys.\n",
        "        if not all(key in story for key in required_keys):\n",
        "            print(f\"Validation Failed: Story at index {i} is missing one or more required keys.\")\n",
        "            is_valid = False\n",
        "            continue # Don't bother with further checks for this invalid story\n",
        "        \n",
        "        # Check that the acceptance criteria is a list with at least one item.\n",
        "        ac = story.get('acceptance_criteria')\n",
        "        if not isinstance(ac, list) or not ac:\n",
        "            print(f\"Validation Failed: Story at index {i} ('{story.get('id')}') has invalid or empty acceptance criteria.\")\n",
        "            is_valid = False\n",
        "\n",
        "    # Only save the artifact if all stories in the list are valid.\n",
        "    if is_valid:\n",
        "        print(\"\\nAll user stories passed validation.\")\n",
        "        artifact_path = \"artifacts/user_stories.json\"\n",
        "        \n",
        "        # Use the helper function to save the file, creating the 'artifacts' directory if needed.\n",
        "        # We use json.dumps with an indent to make the saved file human-readable.\n",
        "        save_artifact(json.dumps(stories_data, indent=2), artifact_path)\n",
        "    else:\n",
        "        print(\"\\nValidation failed. Artifact not saved.\")\n",
        "\n",
        "# Run the validation function on the data we parsed from the LLM.\n",
        "if 'user_stories_json' in locals() and user_stories_json:\n",
        "    validate_and_save_stories(user_stories_json)\n",
        "else:\n",
        "    print(\"Skipping validation as user_stories_json is empty or could not be parsed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab Conclusion\n",
        "\n",
        "Congratulations! You have completed the first lab. You started with a vague, one-sentence problem and finished with a structured, validated, machine-readable requirements artifact. This is the critical first step in an AI-assisted software development lifecycle. The `user_stories.json` file you created will be the direct input for our next lab, where we will generate a formal Product Requirements Document (PRD)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}