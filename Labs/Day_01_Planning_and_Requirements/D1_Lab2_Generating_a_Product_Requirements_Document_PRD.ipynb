{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Lab 2: Generating a Product Requirements Document (PRD)\n",
    "\n",
    "**Objective:** Use the structured `day1_user_stories.json` artifact from the previous lab to generate a formal, comprehensive Product Requirements Document (PRD) in markdown format.\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "With a validated set of user stories, we can now create a higher-level planning document: the PRD. A PRD serves as the source of truth for the product team, outlining the project's purpose, features, and requirements. In this lab, you will use an LLM to synthesize the detailed user stories into this formal document.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "This initial block sets up our environment. It adds the project's root directory to the Python path, allowing us to import our custom `utils.py` script. We then initialize the connection to our Large Language Model (LLM) and load the JSON artifact from the previous lab.\n",
    "\n",
    "**Model Selection:**\n",
    "You can change the `model_name` parameter in the `setup_llm_client()` function to any of the models listed in `utils.py`, such as `\"gemini-2.5-flash\"` or `\"meta-llama/Llama-3.3-70B-Instruct\"`.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the user stories JSON file and the PRD template.\n",
    "- `save_artifact()`: To save our generated PRD and Pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM Client configured: Using 'openai' with model 'gpt-4o'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in 'labs/Day_01_.../'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact\n",
    "\n",
    "# Initialize the LLM client. You can change the model here.\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "\n",
    "# Load the artifact from Lab 1\n",
    "user_stories_str = load_artifact(\"artifacts/day1_user_stories.json\")\n",
    "if user_stories_str:\n",
    "    user_stories_data = json.loads(user_stories_str)\n",
    "else:\n",
    "    user_stories_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Generating a Simple PRD\n",
    "\n",
    "**Task:** Use the loaded user stories to generate a simple PRD.\n",
    "\n",
    "**Instructions:**\n",
    "1. Create a prompt that instructs the LLM to act as a Product Manager.\n",
    "2. Provide the `user_stories_data` as context.\n",
    "3. Ask the LLM to generate a PRD with three sections: \"Introduction\", \"User Personas\", and \"Features / User Stories\".\n",
    "\n",
    "**Expected Quality:** A clean markdown document that correctly summarizes the provided user stories into the requested sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Simple PRD ---\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate a simple PRD.\n",
    "simple_prd_prompt = f\"\"\"\n",
    "# Your prompt here\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Simple PRD ---\")\n",
    "if user_stories_data:\n",
    "    simple_prd_output = get_completion(simple_prd_prompt, client, model_name, api_provider)\n",
    "    print(simple_prd_output)\n",
    "else:\n",
    "    print(\"Skipping PRD generation because user stories are missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating a PRD from a Template\n",
    "\n",
    "**Task:** Instead of just listing sections, we will now provide the LLM with a formal template to ensure the PRD's structure is consistent and complete.\n",
    "\n",
    "**Instructions:**\n",
    "1. First, load the contents of `templates/prd_template.md` into a variable.\n",
    "2. Create a new prompt that instructs the LLM to act as a Senior Product Manager.\n",
    "3. Provide both the `user_stories_data` and the `prd_template_content` as context.\n",
    "4. Instruct the LLM to populate the template with the information from the user stories, ensuring every section of the template is filled out.\n",
    "\n",
    "> **Tip:** The template has sections like 'Success Metrics' and 'Out of Scope' that aren't in the user stories. This is your chance to guide the LLM's creativity! Instruct it to infer logical content for these sections based on the project's overall goal.\n",
    "\n",
    "**Expected Quality:** A complete PRD that strictly follows the structure of the provided template file, demonstrating the LLM's ability to perform structured content generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating PRD from Template ---\n",
      "It looks like you may have started a message but didn't finish it. How can I assist you today? If you have a question or need information on a specific topic, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "# Load the PRD template\n",
    "prd_template_content = load_artifact(\"templates/prd_template.md\")\n",
    "\n",
    "# TODO: Write a prompt to populate the PRD template.\n",
    "template_prd_prompt = f\"\"\"\n",
    "# Your prompt here\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating PRD from Template ---\")\n",
    "if user_stories_data and prd_template_content:\n",
    "    prd_from_template_output = get_completion(template_prd_prompt, client, model_name, api_provider)\n",
    "    print(prd_from_template_output)\n",
    "else:\n",
    "    print(\"Skipping PRD generation because user stories or template are missing.\")\n",
    "    prd_from_template_output = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Programmatic Validation with Pydantic\n",
    "\n",
    "**Task:** We will now create a Pydantic model to represent the structure of our PRD. This allows us to programmatically validate any PRD, ensuring it meets our standards before it's accepted as a formal artifact.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Prompt the LLM to generate a Pydantic model that reflects the structure of the `prd_template.md`. The model should have fields for each major section (e.g., `introduction: str`, `user_personas: List[str]`, `user_stories: List[Dict]`).\n",
    "2.  Save this generated model code to a file named `app/validation_models/prd_model.py`.\n",
    "3.  While we won't write the full validation script in this lab, generating the Pydantic model itself is the key advanced step. It creates a reusable, code-based standard for our documentation.\n",
    "\n",
    "**Expected Quality:** A Python file containing a valid Pydantic model that can be used in the future to validate PRD documents automatically. This represents a shift from manual document review to automated governance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Pydantic Model for PRD ---\n",
      "\n",
      "--- Generated Pydantic Model ---\n",
      "from datetime import date\n",
      "from typing import List, Optional, Dict, Tuple\n",
      "from pydantic import BaseModel\n",
      "\n",
      "class UserStory(BaseModel):\n",
      "    story: str\n",
      "    acceptance_criteria: List[str]\n",
      "\n",
      "class PersonaScenario(BaseModel):\n",
      "    persona: str\n",
      "    scenario: str\n",
      "\n",
      "class Goal(BaseModel):\n",
      "    goal: str\n",
      "    kpi: str\n",
      "    target: str\n",
      "\n",
      "class NonFunctionalRequirement(BaseModel):\n",
      "    category: str\n",
      "    description: str\n",
      "\n",
      "class Milestone(BaseModel):\n",
      "    version: str\n",
      "    target_date: Optional[date]\n",
      "    features: List[str]\n",
      "\n",
      "class OutOfScope(BaseModel):\n",
      "    description: str\n",
      "\n",
      "class FutureWork(BaseModel):\n",
      "    description: str\n",
      "\n",
      "class AppendixItem(BaseModel):\n",
      "    type: str\n",
      "    description: str\n",
      "\n",
      "class ProductRequirementsDocument(BaseModel):\n",
      "    title: str\n",
      "    status: str\n",
      "    author: str\n",
      "    version: str\n",
      "    last_updated: Optional[date]\n",
      "    executive_summary: str\n",
      "    vision: str\n",
      "    problem_statement: str\n",
      "    user_personas_scenarios: List[PersonaScenario]\n",
      "    goals_and_metrics: List[Goal]\n",
      "    user_stories: List[UserStory]\n",
      "    non_functional_requirements: List[NonFunctionalRequirement]\n",
      "    release_plan: List[Milestone]\n",
      "    out_of_scope: List[OutOfScope]\n",
      "    future_considerations: List[FutureWork]\n",
      "    appendix: List[AppendixItem]\n",
      "\n",
      "# Example usage:\n",
      "prd = ProductRequirementsDocument(\n",
      "    title=\"Product Requirements Document: Example Product\",\n",
      "    status=\"Draft\",\n",
      "    author=\"Team Example\",\n",
      "    version=\"1.0\",\n",
      "    last_updated=date(2023, 10, 5),\n",
      "    executive_summary=\"This product aims to streamline onboarding for new hires by providing a centralized, user-friendly platform.\",\n",
      "    vision=\"To enhance productivity and engagement for new hires by reducing onboarding friction.\",\n",
      "    problem_statement=\"New hires currently face a fragmented and overwhelming onboarding experience...\",\n",
      "    user_personas_scenarios=[\n",
      "        PersonaScenario(persona=\"The New Hire\", scenario=\"Faces confusion with multiple onboarding platforms.\"),\n",
      "        PersonaScenario(persona=\"The Hiring Manager\", scenario=\"Spends excessive time answering repetitive questions.\"),\n",
      "        PersonaScenario(persona=\"The HR Coordinator\", scenario=\"Handles high volume of support tickets.\")\n",
      "    ],\n",
      "    goals_and_metrics=[\n",
      "        Goal(goal=\"Improve New Hire Efficiency\", kpi=\"Reduce time-to-first-contribution\", target=\"Decrease by 20% in Q1\"),\n",
      "        Goal(goal=\"Reduce Support Load\", kpi=\"Decrease repetitive questions to HR\", target=\"30% reduction in support tickets\"),\n",
      "        Goal(goal=\"Increase Engagement\", kpi=\"Onboarding completion rate\", target=\"Achieve 95% completion rate\")\n",
      "    ],\n",
      "    user_stories=[\n",
      "        UserStory(\n",
      "            story=\"As a New Hire, I want to log in with my company credentials, so that I can access the onboarding platform securely.\",\n",
      "            acceptance_criteria=[\n",
      "                \"Given I am on the login page, when I enter my valid SSO credentials, then I am redirected to my personal dashboard.\",\n",
      "                \"Given I am on the login page, when I enter invalid credentials, then I see a clear error message.\"\n",
      "            ]\n",
      "        )\n",
      "    ],\n",
      "    non_functional_requirements=[\n",
      "        NonFunctionalRequirement(category=\"Performance\", description=\"The application must load in under 3 seconds on a standard corporate network connection.\"),\n",
      "        NonFunctionalRequirement(category=\"Security\", description=\"All data must be encrypted in transit and at rest. The system must comply with company SSO policies.\"),\n",
      "        NonFunctionalRequirement(category=\"Accessibility\", description=\"The user interface must be compliant with WCAG 2.1 AA standards.\"),\n",
      "        NonFunctionalRequirement(category=\"Scalability\", description=\"The system must support up to 500 concurrent users during peak onboarding seasons.\")\n",
      "    ],\n",
      "    release_plan=[\n",
      "        Milestone(version=\"1.0 (MVP)\", target_date=date(2023, 12, 1), features=[\"Core features including user login\", \"task checklist\", \"document repository\"]),\n",
      "        Milestone(version=\"1.1\", target_date=date(2024, 3, 1), features=[\"Mentorship connection\", \"team introduction features\"]),\n",
      "        Milestone(version=\"2.0\", target_date=date(2024, 6, 1), features=[\"Full social engagement\", \"gamification elements\"])\n",
      "    ],\n",
      "    out_of_scope=[\n",
      "        OutOfScope(description=\"Direct integration with third-party HR payroll systems.\"),\n",
      "        OutOfScope(description=\"A native mobile application (the web app will be mobile-responsive).\"),\n",
      "        OutOfScope(description=\"Advanced analytics dashboard for managers.\")\n",
      "    ],\n",
      "    future_considerations=[\n",
      "        FutureWork(description=\"Integration with the corporate Learning Management System (LMS).\"),\n",
      "        FutureWork(description=\"AI-powered personalized learning paths for new hires.\")\n",
      "    ],\n",
      "    appendix=[\n",
      "        AppendixItem(type=\"Open Question\", description=\"Which team will be responsible for maintaining the content in the document repository?\"),\n",
      "        AppendixItem(type=\"Dependency\", description=\"The final UI design mockups are required from the Design team by [Date].\")\n",
      "    ]\n",
      ")\n",
      "âœ… Successfully saved artifact to: app/validation_models/prd_model.py\n",
      "âœ… Successfully saved artifact to: artifacts/day1_prd.md\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate a Pydantic model for the PRD.\n",
    "# Tip: Be specific. Tell the LLM to create a class named 'ProductRequirementsDocument' and to use appropriate types from Python's 'typing' library.\n",
    "pydantic_model_prompt = f\"\"\"\n",
    "Generate a Pydantic model for the Product Requirements Document (PRD) based on the following template content:\n",
    "{prd_template_content}.\n",
    "The model should be named 'ProductRequirementsDocument' and should use appropriate types from Python's 'typing' library.\n",
    "The model should include fields for each section of the PRD, such as 'title', 'description', 'user_stories', 'features', and any other relevant sections.\n",
    "Make sure to include type annotations for each field, and use Pydantic's BaseModel as the base class.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Pydantic Model for PRD ---\")\n",
    "if prd_template_content:\n",
    "    pydantic_model_code = get_completion(pydantic_model_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the code if it's wrapped in markdown fences\n",
    "    if '```' in pydantic_model_code:\n",
    "        pydantic_model_code = pydantic_model_code.split('```')[1].lstrip('python').strip()\n",
    "    \n",
    "    print(\"\\n--- Generated Pydantic Model ---\")\n",
    "    print(pydantic_model_code)\n",
    "\n",
    "    # Save the generated Pydantic model code to a file.\n",
    "    model_path = \"app/validation_models/prd_model.py\"\n",
    "    save_artifact(pydantic_model_code, model_path)\n",
    "else:\n",
    "    print(\"Skipping Pydantic model generation because template is missing.\")\n",
    "\n",
    "# Finally, save the completed PRD from the intermediate challenge\n",
    "if prd_from_template_output:\n",
    "    save_artifact(prd_from_template_output, \"artifacts/day1_prd.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent work! You have now taken the structured user stories from the first lab and synthesized them into a formal Product Requirements Document. You also created a Pydantic model to enforce the structure of this document, introducing automated governance into your workflow. The `day1_prd.md` artifact will be the primary input for Day 2, where we will begin designing our system's architecture and database.\n",
    "\n",
    "> **Key Takeaway:** Using an LLM to populate a pre-defined template is a powerful pattern for creating consistent, high-quality documentation at scale. It combines the LLM's language skills with your required structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
