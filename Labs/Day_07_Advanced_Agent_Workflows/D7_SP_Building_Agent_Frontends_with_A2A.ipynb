{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 7 - Self-Paced Practice Lab: Building Agent Frontends with A2A\n",
        "\n",
        "**Objective:** Reinforce the concepts of Day 7 by using the A2A Framework to build a simple, guided user interface for generating SQL queries.\n",
        "\n",
        "**Estimated Time:** 45 minutes (Self-Paced)\n",
        "\n",
        "**Introduction:**\n",
        "Often, users know what they want to achieve but don't know how to ask for it in a way an AI can best understand. The A2A (Ask-Advise-Act) framework helps solve this by creating a guided conversation. In this lab, you will build a simple Streamlit application that uses A2A to help a non-technical user generate a SQL query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the project's root directory to the Python path\n",
        "try:\n",
        "    # This works when running as a script\n",
        "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))\n",
        "except NameError:\n",
        "    # This works when running in an interactive environment (like a notebook)\n",
        "    # We go up two levels from the notebook's directory to the project root.\n",
        "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This helper will install packages if they are not found\n",
        "import importlib\n",
        "def install_if_missing(package):\n",
        "    try:\n",
        "        importlib.import_module(package)\n",
        "    except ImportError:\n",
        "        print(f\"{package} not found, installing...\")\n",
        "        %pip install -q {package}\n",
        "\n",
        "install_if_missing('a2a')\n",
        "install_if_missing('streamlit')\n",
        "install_if_missing('langchain_openai')\n",
        "\n",
        "from utils import setup_llm_client\n",
        "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: The Problem Statement\n",
        "\n",
        "Your task is to build a Streamlit app called \"SQL Query Generator\". A user will provide a high-level goal (e.g., \"show me all our customers in California\") and a database schema. The app will use the A2A framework to guide the user to a valid SQL query.\n",
        "\n",
        "**This lab requires you to create and run a Python script (`.py`) file, as Streamlit apps cannot be run directly inside a Jupyter notebook.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Your Task\n",
        "\n",
        "**Task:** Create a Python script named `sql_query_generator.py` that implements the A2A flow.\n",
        "\n",
        "**Instructions:**\n",
        "1.  **Setup the UI:** Create a Streamlit UI with a text area for the user's goal and another for the database schema.\n",
        "2.  **Ask Phase:** When the user clicks \"Generate Query\", your app should first enter the **Ask** phase. It should ask the LLM to generate 1-2 clarifying questions based on the user's goal and schema (e.g., \"Should the results be ordered by a specific column?\"). Display these questions to the user with text input boxes for their answers.\n",
        "3.  **Advise Phase:** Once the user answers the clarifying questions, enter the **Advise** phase. Send the original goal, the schema, the clarifying questions, and the user's answers to the LLM. Ask the LLM to create a step-by-step \"plan\" for how it will construct the query.\n",
        "4.  **Act Phase:** Finally, enter the **Act** phase. Send the plan and all previous context to the LLM and ask it to generate the final SQL query.\n",
        "5.  Display the final SQL query to the user in a code block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create a file named 'sql_query_generator.py' and add the following code.\n",
        "# You will need to complete the prompts for each phase of the A2A flow.\n",
        "\n",
        "sql_app_code = \"\"\"\n",
        "import streamlit as st\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "st.title(\"SQL Query Generator with A2A\")\n",
        "\n",
        "schema = st.text_area(\"Database Schema\", height=150, placeholder=\"CREATE TABLE customers (...)\")\n",
        "goal = st.text_area(\"What is your goal?\", placeholder=\"Show me all customers in California ordered by last name.\")\n",
        "\n",
        "if 'questions' not in st.session_state:\n",
        "    st.session_state.questions = []\n",
        "if 'answers' not in st.session_state:\n",
        "    st.session_state.answers = []\n",
        "if 'plan' not in st.session_state:\n",
        "    st.session_state.plan = \"\"\n",
        "if 'query' not in st.session_state:\n",
        "    st.session_state.query = \"\"\n",
        "\n",
        "if st.button(\"Start Query Generation\"):\n",
        "    # --- ASK PHASE ---\n",
        "    ask_prompt = f''' # Your Ask Phase Prompt Here '''\n",
        "    response = llm.invoke(ask_prompt).content\n",
        "    st.session_state.questions = [q for q in response.split('?') if q]\n",
        "    st.session_state.answers = [\"\" for _ in st.session_state.questions]\n",
        "    st.session_state.plan = \"\"\n",
        "    st.session_state.query = \"\"\n",
        "\n",
        "if st.session_state.questions:\n",
        "    st.subheader(\"Ask: Clarifying Questions\")\n",
        "    for i, q in enumerate(st.session_state.questions):\n",
        "        st.session_state.answers[i] = st.text_input(f\"{q}?\", key=f\"ans{i}\")\n",
        "    \n",
        "    if st.button(\"Submit Answers & Get Plan\"):\n",
        "        # --- ADVISE PHASE ---\n",
        "        advise_prompt = f''' # Your Advise Phase Prompt Here '''\n",
        "        st.session_state.plan = llm.invoke(advise_prompt).content\n",
        "\n",
        "if st.session_state.plan:\n",
        "    st.subheader(\"Advise: Query Plan\")\n",
        "    st.markdown(st.session_state.plan)\n",
        "    if st.button(\"Generate Final Query\"):\n",
        "        # --- ACT PHASE ---\n",
        "        act_prompt = f''' # Your Act Phase Prompt Here '''\n",
        "        st.session_state.query = llm.invoke(act_prompt).content\n",
        "\n",
        "if st.session_state.query:\n",
        "    st.subheader(\"Act: Final SQL Query\")\n",
        "    st.code(st.session_state.query, language='sql')\n",
        "\"\"\"\n",
        "\n",
        "from utils import save_artifact\n",
        "save_artifact(sql_app_code, \"sql_query_generator.py\")\n",
        "print(\"Saved 'sql_query_generator.py'. To run it, open your terminal and execute: streamlit run sql_query_generator.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab Conclusion\n",
        "\n",
        "Congratulations! You have built a practical application using the A2A framework to create a guided, conversational experience. This pattern is incredibly powerful for turning complex tasks (like writing SQL) into a simple, step-by-step process for users. You've learned how to break down a problem into the Ask, Advise, and Act phases to create more user-friendly and effective AI tools."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}