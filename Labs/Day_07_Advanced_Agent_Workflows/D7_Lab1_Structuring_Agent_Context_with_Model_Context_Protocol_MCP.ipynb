{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 7 - Lab 1: Structuring Agent Context with Model Context Protocol (MCP)\n",
        "\n",
        "**Objective:** Learn to structure complex prompts for AI agents using the Model Context Protocol (MCP) to improve reliability and clarity, and build a code refactoring agent that leverages this protocol.\n",
        "\n",
        "**Estimated Time:** 135 minutes\n",
        "\n",
        "**Introduction:**\n",
        "Welcome to Day 7! As agentic systems become more complex, sending a simple, unstructured prompt is often not enough. The Model Context Protocol (MCP) provides a standardized, XML-like way to structure the information you send to an agent, clearly separating instructions, user requests, and different types of context. In this lab, you will use the MCP SDK and LangChain adapters to build a more robust and predictable code refactoring agent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup\n",
        "\n",
        "We will install the necessary libraries for this lab, including `model-context-protocol` for creating structured prompts and `langchain-mcp-adapters` for easily integrating MCP with our LangChain agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the project's root directory to the Python path\n",
        "try:\n",
        "    # This works when running as a script\n",
        "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))\n",
        "except NameError:\n",
        "    # This works when running in an interactive environment (like a notebook)\n",
        "    # We go up two levels from the notebook's directory to the project root.\n",
        "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This helper will install packages if they are not found\n",
        "import importlib\n",
        "def install_if_missing(package):\n",
        "    try:\n",
        "        importlib.import_module(package)\n",
        "    except ImportError:\n",
        "        print(f\"{package} not found, installing...\")\n",
        "        %pip install -q {package}\n",
        "\n",
        "install_if_missing('model_context_protocol')\n",
        "install_if_missing('langchain_mcp_adapters')\n",
        "install_if_missing('langchain_openai')\n",
        "\n",
        "from utils import setup_llm_client\n",
        "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: The Challenges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 1 (Foundational): Manually Formatting an MCP Prompt\n",
        "\n",
        "**Task:** Before using the SDK, manually write a prompt string that follows the MCP XML-style format.\n",
        "\n",
        "**Instructions:**\n",
        "1.  Create a multi-line f-string for your prompt.\n",
        "2.  The prompt should include the following MCP tags:\n",
        "    * `<request>`: The user's high-level request (e.g., \"Please refactor this code.\").\n",
        "    * `<context>`: A container for contextual information.\n",
        "    * `<code>`: Inside `<context>`, place a snippet of Python code that needs refactoring.\n",
        "    * `<instructions>`: Inside `<context>`, provide specific instructions for the refactoring (e.g., \"Make this function more readable and add type hints.\").\n",
        "3.  Send this manually formatted string to the LLM and observe the output.\n",
        "\n",
        "**Expected Quality:** A successful response from the LLM, demonstrating that it can understand and act upon the structured MCP format even without the SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=model_name)\n",
        "\n",
        "code_to_refactor = \"def my_func(a,b):\\n  x=a+b\\n  y=x*2\\n  return y\"\n",
        "\n",
        "# TODO: Create a prompt string that manually uses MCP tags.\n",
        "manual_mcp_prompt = f\"\"\"\n",
        "# Your prompt here\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- Sending Manually Formatted MCP Prompt ---\")\n",
        "response = llm.invoke(manual_mcp_prompt)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 2 (Intermediate): Using the MCP SDK to Build a Prompt\n",
        "\n",
        "**Task:** Now, use the `model-context-protocol` SDK to programmatically build the same structured prompt.\n",
        "\n",
        "**Instructions:**\n",
        "1.  Import `Request`, `Context`, `Code`, and `Instructions` from the `model_context_protocol` library.\n",
        "2.  Create an instance of the `Code` context item, passing the `code_to_refactor`.\n",
        "3.  Create an instance of the `Instructions` context item.\n",
        "4.  Create a `Context` object, passing a list containing your `Code` and `Instructions` items.\n",
        "5.  Create the final `Request` object, passing the user's request text and the `Context` object.\n",
        "6.  Use the `.render()` method on the `Request` object to get the formatted string and print it to verify it matches your manual prompt.\n",
        "\n",
        "**Expected Quality:** A Python script that programmatically generates a valid MCP-formatted string, demonstrating a more robust and maintainable way to construct complex prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model_context_protocol import Request, Context, Code, Instructions\n",
        "\n",
        "# TODO: Use the MCP SDK to build the request programmatically.\n",
        "\n",
        "# 1. Create Code and Instructions items\n",
        "code_item = None # Your code here\n",
        "instructions_item = None # Your code here\n",
        "\n",
        "# 2. Create the Context object\n",
        "context_obj = None # Your code here\n",
        "\n",
        "# 3. Create the final Request object\n",
        "mcp_request = None # Your code here\n",
        "\n",
        "# 4. Render the request to a string\n",
        "rendered_prompt = mcp_request.render()\n",
        "\n",
        "print(\"--- Programmatically Rendered MCP Prompt ---\")\n",
        "print(rendered_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 3 (Advanced): Building a Context-Aware Refactoring Agent\n",
        "\n",
        "**Task:** Use the `langchain-mcp-adapters` library to create a LangChain agent that automatically structures its inputs using MCP.\n",
        "\n",
        "**Instructions:**\n",
        "1.  Import `McpChatPromptTemplate` from `langchain_mcp_adapters`.\n",
        "2.  Create a list of context builders. For this lab, you'll need one for `Code` and one for `Instructions`. The adapter library provides these.\n",
        "3.  Create an instance of `McpChatPromptTemplate`, passing in your list of context builders and a request template string.\n",
        "4.  Create a simple LangChain chain by piping this special prompt template to your LLM.\n",
        "5.  Invoke the chain. The input should be a dictionary containing keys that match your context builders (e.g., `code` and `instructions`) and your request template variables.\n",
        "6.  The adapter will automatically build the full MCP-formatted prompt before sending it to the LLM.\n",
        "\n",
        "**Expected Quality:** A functioning LangChain agent that seamlessly and automatically uses the Model Context Protocol, demonstrating how to build robust, production-ready agents that handle complex, multi-part context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_mcp_adapters import McpChatPromptTemplate\n",
        "from langchain_mcp_adapters.context_builders import CodeContextBuilder, InstructionsContextBuilder\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# TODO: 1. Create a list of context builders\n",
        "context_builders = [] # Your list here\n",
        "\n",
        "# TODO: 2. Create the McpChatPromptTemplate\n",
        "mcp_prompt_template = None # Your prompt template here\n",
        "\n",
        "# TODO: 3. Create the LangChain agent chain\n",
        "refactoring_agent = None # Your chain here\n",
        "\n",
        "# TODO: 4. Invoke the agent with a dictionary of inputs\n",
        "refactoring_input = {\n",
        "    \"user_request\": \"Please refactor this code to be more Pythonic.\",\n",
        "    \"code\": \"def f(data):\\n  r = []\\n  for i in data:\\n    if i % 2 == 0:\\n      r.append(i*i)\\n  return r\",\n",
        "    \"instructions\": \"Use a list comprehension and add type hints.\"\n",
        "}\n",
        "\n",
        "print(\"--- Invoking MCP-powered Refactoring Agent ---\")\n",
        "refactored_code = refactoring_agent.invoke(refactoring_input)\n",
        "print(refactored_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab Conclusion\n",
        "\n",
        "Excellent work! You have learned how to use the Model Context Protocol to create structured, reliable prompts for your AI agents. You progressed from manually writing MCP-formatted strings to using the SDK for programmatic construction, and finally to using the LangChain adapter for seamless integration. This skill is crucial for building advanced agents that need to handle diverse and complex contextual information in a predictable way."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}