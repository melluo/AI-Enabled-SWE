{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 7 - Lab 2: Building Agent Frontends with the A2A Framework\n",
        "\n",
        "**Objective:** Use the A2A (Ask-Advise-Act) Framework to build a guided, conversational user interface for an AI agent.\n",
        "\n",
        "**Estimated Time:** 135 minutes\n",
        "\n",
        "**Introduction:**\n",
        "A powerful agent is only effective if users can interact with it easily. Often, users know their goal but not how to phrase it for an AI. The A2A Framework solves this by creating a guided dialogue. In this lab, you will build a Streamlit application that uses A2A to help a non-technical user generate a complex SQL query by breaking the process down into three steps: Ask, Advise, and Act."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup\n",
        "\n",
        "We will need to install the `a2a` and `streamlit` libraries. Note that this lab requires you to create and run a standalone Python script (`.py`), as Streamlit applications are not run inside Jupyter notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the project's root directory to the Python path\n",
        "try:\n",
        "    # This works when running as a script\n",
        "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))\n",
        "except NameError:\n",
        "    # This works when running in an interactive environment (like a notebook)\n",
        "    # We go up two levels from the notebook's directory to the project root.\n",
        "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a2a not found, installing...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: Building 'a2a' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'a2a'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "âœ… LLM Client configured: Using 'openai' with model 'gpt-4o'\n"
          ]
        }
      ],
      "source": [
        "# This helper will install packages if they are not found\n",
        "import importlib\n",
        "def install_if_missing(package):\n",
        "    try:\n",
        "        importlib.import_module(package)\n",
        "    except ImportError:\n",
        "        print(f\"{package} not found, installing...\")\n",
        "        %pip install -q {package}\n",
        "\n",
        "install_if_missing('a2a')\n",
        "install_if_missing('streamlit')\n",
        "install_if_missing('langchain_openai')\n",
        "\n",
        "from utils import setup_llm_client, save_artifact\n",
        "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: The Problem Statement\n",
        "\n",
        "Your task is to build a Streamlit app called \"SQL Query Generator\". A user will provide a high-level goal (e.g., \"show me all our customers in California\") and a database schema. The app will use the A2A framework to guide the user to a valid SQL query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Your Task\n",
        "\n",
        "**Task:** Create a Python script named `sql_query_generator.py` that implements the A2A flow.\n",
        "\n",
        "**Instructions:**\n",
        "1.  **Setup the UI:** Create a Streamlit UI with a text area for the user's goal and another for the database schema.\n",
        "2.  **Ask Phase:** When the user clicks \"Generate Query\", your app should first enter the **Ask** phase. It should ask the LLM to generate 1-2 clarifying questions based on the user's goal and schema (e.g., \"Should the results be ordered by a specific column?\"). Display these questions to the user with text input boxes for their answers.\n",
        "3.  **Advise Phase:** Once the user answers the clarifying questions, enter the **Advise** phase. Send the original goal, the schema, the clarifying questions, and the user's answers to the LLM. Ask the LLM to create a step-by-step \"plan\" for how it will construct the query.\n",
        "4.  **Act Phase:** Finally, enter the **Act** phase. Send the plan and all previous context to the LLM and ask it to generate the final SQL query.\n",
        "5.  Display the final SQL query to the user in a code block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create a file named 'sql_query_generator.py' and add the following code.\n",
        "# You will need to complete the prompts for each phase of the A2A flow.\n",
        "\n",
        "sql_app_code = \"\"\"\n",
        "import streamlit as st\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "st.title(\"SQL Query Generator with A2A\")\n",
        "\n",
        "schema = st.text_area(\"Database Schema\", height=150, placeholder=\"CREATE TABLE customers (...)\")\n",
        "goal = st.text_area(\"What is your goal?\", placeholder=\"Show me all customers in California ordered by last name.\")\n",
        "\n",
        "# Initialize session state variables\n",
        "if 'step' not in st.session_state:\n",
        "    st.session_state.step = \"START\"\n",
        "\n",
        "if st.button(\"Generate Query\"):\n",
        "    if schema and goal:\n",
        "        st.session_state.step = \"ASK\"\n",
        "        # --- ASK PHASE ---\n",
        "        ask_prompt = f''' # Your Ask Phase Prompt Here '''\n",
        "        response = llm.invoke(ask_prompt).content\n",
        "        st.session_state.questions = [q.strip() for q in response.split('?') if q.strip()]\n",
        "        st.session_state.answers = [\"\" for _ in st.session_state.questions]\n",
        "    else:\n",
        "        st.error(\"Please provide both a schema and a goal.\")\n",
        "\n",
        "if st.session_state.step == \"ASK\" and 'questions' in st.session_state:\n",
        "    st.subheader(\"Ask: Clarifying Questions\")\n",
        "    for i, q in enumerate(st.session_state.questions):\n",
        "        st.session_state.answers[i] = st.text_input(f\"{q}?\", key=f\"ans{i}\")\n",
        "    \n",
        "    if st.button(\"Submit Answers\"):\n",
        "        st.session_state.step = \"ADVISE\"\n",
        "        # --- ADVISE PHASE ---\n",
        "        advise_prompt = f''' # Your Advise Phase Prompt Here '''\n",
        "        st.session_state.plan = llm.invoke(advise_prompt).content\n",
        "        st.experimental_rerun()\n",
        "\n",
        "if st.session_state.step == \"ADVISE\" and 'plan' in st.session_state:\n",
        "    st.subheader(\"Advise: Query Plan\")\n",
        "    st.markdown(st.session_state.plan)\n",
        "    if st.button(\"Looks Good, Generate SQL\"):\n",
        "        st.session_state.step = \"ACT\"\n",
        "        # --- ACT PHASE ---\n",
        "        act_prompt = f''' # Your Act Phase Prompt Here '''\n",
        "        query = llm.invoke(act_prompt).content\n",
        "        if '```' in query:\n",
        "            query = query.split('```')[1].lstrip('sql').strip()\n",
        "        st.session_state.query = query\n",
        "        st.experimental_rerun()\n",
        "\n",
        "if st.session_state.step == \"ACT\" and 'query' in st.session_state:\n",
        "    st.subheader(\"Act: Final SQL Query\")\n",
        "    st.code(st.session_state.query, language='sql')\n",
        "\"\"\"\n",
        "\n",
        "from utils import save_artifact\n",
        "save_artifact(sql_app_code, \"labs/Day_07_Advanced_Agent_Workflows/sql_query_generator.py\")\n",
        "print(\"Saved 'sql_query_generator.py'. To run it, open your terminal and execute: streamlit run labs/Day_07_Advanced_Agent_Workflows/sql_query_generator.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab Conclusion\n",
        "\n",
        "Congratulations! You have built a practical application using the A2A framework to create a guided, conversational experience. This pattern is incredibly powerful for turning complex tasks (like writing SQL) into a simple, step-by-step process for users. You've learned how to break down a problem into the Ask, Advise, and Act phases to create more user-friendly and effective AI tools."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
