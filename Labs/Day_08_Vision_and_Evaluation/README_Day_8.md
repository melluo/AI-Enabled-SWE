# Day 8: Vision & Evaluation

## Overview

  * **Synopsis:** Today, we explore the cutting edge of AI-driven development. First, you will learn to build agents that can *see*, translating visual designs directly into functional frontend code. Then, you will learn the critical lifecycle of a production AI system: how to rigorously evaluate its performance, implement safety guardrails, and use adversarial "Red Team" agents to proactively find and fix vulnerabilities.
  * **Core Question of the Day:** How can we build agents that understand visual information, and how do we prove that our AI systems are safe, reliable, and robust?
  * **Key Artifacts Produced:**
      * `artifacts/design_review.md`: A markdown file containing an automated UI/UX review of AI-generated code against a design image.
      * A quantitative evaluation (in JSON format) of our RAG agent's performance.
      * A list of adversarial prompts generated by a "Red Team" agent to test our system's defenses.

## Learning Objectives

By the end of today's labs, you will be able to:

  * Use a multi-modal vision model to generate React and Tailwind CSS code directly from a UI screenshot.
  * Implement an AI-on-AI workflow where one agent critiques the code generated by another.
  * Evaluate an agent's performance quantitatively using the "LLM-as-a-Judge" pattern.
  * Implement input and output safety guardrails to protect an agent from prompt injection and hallucination.
  * Generate adversarial prompts with a "Red Team" agent to proactively discover security vulnerabilities.

## Agenda & Labs Covered

  * **Lab 1: Vision-Enabled UI/UX Agents** - Generate a React component from a design image and then use a second "critic" agent to perform an automated design review.
  * **Lab 2: Evaluating and "Red Teaming" an Agent** - Evaluate our RAG agent's quality, implement security guardrails, and build a "Red Team" agent to attack its defenses.
  * **Self-Paced Practice: Building a Weather App UI** - Apply the vision-to-code skill to generate the UI for a mobile weather application.

## üõ†Ô∏è Prerequisites & Setup

This section provides the essential setup steps for a smooth lab experience.

  * **Software Requirements:**
      * VS Code with the Jupyter and Python extensions.
  * **Environment Setup:**
      * Ensure your Python virtual environment is activated.
        ```bash
        # On macOS/Linux:
        source .venv/bin/activate
        ```
  * **API Keys & Configuration:**
      * Your `.env` file must be correctly configured.
      * **Crucially, for Lab 1, you must select a vision-capable model** in your `setup_llm_client()` function call (e.g., `model_name="gpt-4o"`). The notebook specifies this requirement.

## üí° Core Concepts & Value Proposition

  * **Concept 1: Vision-to-Code:** This is a revolutionary capability that bridges the gap between design and development. By understanding images, an AI agent can interpret a visual mockup and generate the corresponding code, dramatically accelerating the process of building user interfaces.
  * **Concept 2: The Generate -\> Refactor -\> Critique Workflow:** This is a powerful, iterative pattern for AI-assisted development.
    1.  **Generate:** Create a first draft of code from a high-level prompt (or an image).
    2.  **Refactor:** Use an agent to improve the code's structure and quality.
    3.  **Critique:** Use a specialized "critic" agent to automatically review the work for correctness or adherence to design, generating a list of improvements for the next iteration.
  * **Concept 3: The AI System Lifecycle (Build, Evaluate, Secure, Attack):** Building an agent is only the beginning. A production-ready AI system requires a full lifecycle of quality assurance. This includes **Evaluation** (scoring performance with an LLM-as-a-Judge), **Securing** (adding guardrails), and **Attacking** (using a Red Team agent to find weaknesses before they are exploited).
  * **"Why it Matters":** The skills you learn today will help you build AI systems that are both state-of-the-art in their capabilities (vision) and production-ready in their quality and security. This is what separates hobby projects from professional, trustworthy AI applications.

## üöÄ Step-by-Step Lab Instructions

### Lab 1: Vision-Enabled UI/UX Agents

1.  **Open the Notebook:** `labs/Day_08_Vision_and_Evaluation/D8_Lab1_Vision_Enabled_UI_UX_Agents.ipynb`
2.  **Goal:** To perform a complete, AI-assisted frontend workflow: generate a React component from an image, refactor it, and perform an automated design review.
3.  **Execution:**
      * Ensure you are using a vision-capable model as specified in the notebook's setup cell.
      * Run the cells in order, completing the `TODO` blocks to write prompts for the generator, refactor, and critic agents.
4.  **Tool-Specific Guidance:**
      * **VS Code:**
          * **For Newcomers:** The Jupyter extension in VS Code is excellent for vision labs. The `display(Image(url=...))` command will render the design screenshot directly in your notebook. This allows you to keep the visual design context right next to the code and prompts you are working on.
      * **Git:**
          * The design review is a valuable artifact that provides a record of the AI's QA process. Commit it.
            ```bash
            git add artifacts/design_review.md
            git commit -m "docs: Add automated UI/UX design review"
            ```

### Lab 2: Evaluating and "Red Teaming" an Agent

1.  **Open the Notebook:** `labs/Day_08_Vision_and_Evaluation/D8_Lab2_Evaluating_and_Red_Teaming_an_Agent.ipynb`
2.  **Goal:** To evaluate the quality and security of the RAG agent built on Day 6.
3.  **Execution:**
      * The setup cell in this notebook reconstructs the RAG agent, so it is self-contained.
      * Complete the `TODO` blocks to write prompts for the "LLM-as-a-Judge" and the "Red Team" agent, and to implement the security guardrail functions.
4.  **Tool-Specific Guidance:**
      * **VS Code:**
          * **For Newcomers:** Lab 2 involves wrapping a function with security checks. If you are new to debugging, this is a great opportunity to use VS Code's debugger. You can set a breakpoint inside the `secure_rag_chain` function, run the notebook in debug mode, and step through the code line-by-line to see exactly how the input and output guardrails are triggered.
      * **Git:** The evaluation and red teaming logic is a key part of your project's quality assurance framework. Commit the completed notebook.
        ```bash
        git add labs/Day_08_Vision_and_Evaluation/D8_Lab2_Evaluating_and_Red_Teaming_an_Agent.ipynb
        git commit -m "test: Implement evaluation and red teaming for RAG agent"
        ```

## üîç Troubleshooting & Common Issues

  * **Issue:** In Lab 1, the model returns an error or says it cannot process the image.
      * **Solution:** This almost always means you are not using a vision-capable model. In the first setup cell, ensure your `setup_llm_client()` call specifies a vision model, for example: `setup_llm_client(model_name="gpt-4o")`.
  * **Issue:** In Lab 2, the "LLM-as-a-Judge" returns unstructured text instead of the requested JSON.
      * **Solution:** This is a prompt engineering challenge. The best way to fix it is to make your prompt's output constraint more forceful. For example: "You MUST respond with only a valid JSON object. Your entire response must start with `{` and end with `}`. Do not include any other text, explanations, or markdown."

## ‚úÖ Key Takeaways

  * You have learned to expand an agent's senses to include vision, allowing you to automate workflows that bridge the gap between visual design and code.
  * You have mastered the AI system quality lifecycle, including quantitative evaluation with LLM-as-a-Judge and proactive security testing with Red Team agents.
  * You are now fully equipped with the concepts and skills covering the entire AI-driven SDLC. This knowledge will be the foundation for your success in the capstone project on Days 9 and 10.