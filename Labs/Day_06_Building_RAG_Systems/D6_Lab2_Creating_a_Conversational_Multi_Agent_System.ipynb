{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6 - Lab 2: Creating a Conversational Multi-Agent System\n",
    "\n",
    "**Objective:** Integrate the multi-agent LangGraph system from the previous lab into the FastAPI backend, creating a new `/chat` endpoint that is stateful and can handle conversational memory.\n",
    "\n",
    "**Estimated Time:** 90 minutes\n",
    "\n",
    "**Introduction:**\n",
    "A powerful agent isn't very useful if users can't interact with it. In this lab, you will take the sophisticated multi-agent research team you built in the previous lab and expose it as a conversational API endpoint. This involves integrating the LangGraph application into your FastAPI backend and, most importantly, implementing a mechanism to handle conversational memory, allowing for natural, multi-turn interactions.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "For this lab, you will be working directly in your `app/` directory, primarily modifying your `main.py` file. The goal is to add a new endpoint that can run your LangGraph agent. We will mock the agent object here in the notebook for development and planning purposes before you integrate it into your Python files.\n",
    "\n",
    "**Model Selection:**\n",
    "Since this lab focuses on integration rather than generation, any of the previously used models will work well.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "This lab primarily involves writing application code in `.py` files, but we will use `save_artifact` to save a sample UI file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. The following challenges involve modifying your '.py' files.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import save_artifact\n",
    "print(\"Setup complete. The following challenges involve modifying your '.py' files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges\n",
    "\n",
    "For these challenges, you will be editing your `app/main.py` file and creating a new `chat_ui.py` file in your IDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Creating a Stateless Chat Endpoint\n",
    "\n",
    "**Task:** Create a simple `/chat` endpoint that takes a user's question and returns the agent's response, without any memory.\n",
    "\n",
    "**Instructions:**\n",
    "1.  In your `app/main.py` file, define a new Pantic model `ChatRequest` that has a single field: `question: str`.\n",
    "2.  Create a new `POST /chat` endpoint.\n",
    "3.  This endpoint should take a `ChatRequest` object as its body.\n",
    "4.  Inside the endpoint, call your compiled LangGraph agent's `.invoke()` method with the user's question. For now, you can use a mock object.\n",
    "5.  Return the `answer` from the agent's response.\n",
    "\n",
    "**Expected Quality:** A functional, though stateless, API endpoint that allows a user to ask a single question and get a single answer from the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Building a Simple Streamlit UI\n",
    "\n",
    "**Task:** Create a simple user interface using Streamlit to interact with your new `/chat` endpoint.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a new Python script named `chat_ui.py`.\n",
    "2.  Use Streamlit components to create a title, a text input box for the user's question, and a button to submit.\n",
    "3.  When the button is clicked, use the `requests` library to make a `POST` call to your (locally running) FastAPI server's `/chat` endpoint.\n",
    "4.  Display the agent's response on the page.\n",
    "\n",
    "**Expected Quality:** A functional web interface where a user can type a question, click a button, and see the agent's response, demonstrating a full-stack interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Implementing Conversational Memory\n",
    "\n",
    "**Task:** Refactor your backend to handle stateful, multi-turn conversations. The agent should be able to remember the context of previous messages in the same session.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Modify your `ChatRequest` Pydantic model in `app/main.py` to include an optional `session_id: str = None`.\n",
    "2.  Create a new `POST /stateful_chat` endpoint logic:\n",
    "    * If the incoming request has no `session_id`, generate a new one using `uuid.uuid4()`.\n",
    "    * When calling your LangGraph app's `.invoke()` method, pass a `config` dictionary. This config must contain a `configurable` key with a `session_id` inside it. This is how LangGraph manages stateful conversations.\n",
    "    * Return both the agent's answer and the `session_id` to the client.\n",
    "3.  Update your `chat_ui.py` to store the `session_id` in `st.session_state` and send it back with each subsequent request.\n",
    "\n",
    "**Expected Quality:** A fully conversational chatbot. You should be able to ask a follow-up question (e.g., \"Can you tell me more about that?\") and have the agent understand the context from the previous turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent! You have successfully integrated your powerful multi-agent system into a real-world application. You created a stateless API endpoint, built a UI for it, and then performed the critical upgrade to make it a stateful, conversational agent with memory. This is the complete pattern for deploying sophisticated AI assistants that can engage in natural, multi-turn dialogues with users.\n",
    "\n",
    "> **Key Takeaway:** Stateful conversation is achieved by passing a consistent `session_id` to your agent. Frameworks like LangGraph use this ID to automatically manage and retrieve the history for each user, enabling context-aware, multi-turn conversations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
