{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 - Lab 2: Refactoring & Documentation\n",
    "\n",
    "**Objective:** Use an LLM to refactor a complex Python function to improve its readability and maintainability, and then generate comprehensive, high-quality documentation for the project.\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Writing code is only the first step; writing *good* code is what makes a project successful in the long run. In this lab, you will use an LLM as a code quality expert. You will refactor a poorly written function to make it cleaner and then generate professional-grade documentation, including docstrings and a README file. These are high-value tasks that AI can significantly accelerate.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will set up our environment and define a sample of poorly written code that we will use as the target for our refactoring and documentation efforts.\n",
    "\n",
    "**Model Selection:**\n",
    "Models with strong coding and reasoning abilities are best for this task. `gpt-4.1`, `o3`, or `codex-mini` are great choices. You can also try more general models like `gemini-2.5-pro`.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `save_artifact()`: To save the generated README file.\n",
    "- `clean_llm_output()`: To clean up the generated code and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4o'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, clean_llm_output, load_artifact\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Code to Improve\n",
    "\n",
    "Here is a sample Python function that is functional but poorly written. It's hard to read, has no comments or type hints, and mixes multiple responsibilities. This is the code we will improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_code = \"\"\"\n",
    "def process_data(data, operation):\n",
    "    if operation == 'sum':\n",
    "        total = 0\n",
    "        for i in data:\n",
    "            total += i\n",
    "        return total\n",
    "    elif operation == 'average':\n",
    "        total = 0\n",
    "        for i in data:\n",
    "            total += i\n",
    "        return total / len(data)\n",
    "    elif operation == 'max':\n",
    "        max_val = data[0]\n",
    "        for i in data:\n",
    "            if i > max_val:\n",
    "                max_val = i\n",
    "        return max_val\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Refactoring the Code\n",
    "\n",
    "**Task:** Use the LLM to refactor the `bad_code` to be more readable, efficient, and maintainable.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that instructs the LLM to act as a senior Python developer.\n",
    "2.  Provide the `bad_code` as context.\n",
    "3.  Ask the LLM to refactor the code. Be specific about the improvements you want, such as:\n",
    "    * Breaking the single function into multiple, smaller functions.\n",
    "    * Using built-in Python functions where appropriate (e.g., `sum()`, `max()`).\n",
    "    * Adding clear type hints and return types.\n",
    "\n",
    "> **Tip:** When you ask the AI to refactor, give it a principle to follow. For example, ask it to apply the 'Single Responsibility Principle,' which means each function should do only one thing. This guides the AI to create cleaner, more modular code.\n",
    "\n",
    "**Expected Quality:** A block of Python code that is functionally identical to the original but is significantly cleaner, more modular, and easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Refactoring Code ---\n",
      "from typing import List, Union\n",
      "\n",
      "def calculate_sum(data: List[Union[int, float]]) -> Union[int, float]:\n",
      "    \"\"\"Calculates the sum of the data.\"\"\"\n",
      "    return sum(data)\n",
      "\n",
      "def calculate_average(data: List[Union[int, float]]) -> float:\n",
      "    \"\"\"Calculates the average of the data.\"\"\"\n",
      "    return sum(data) / len(data)\n",
      "\n",
      "def find_max(data: List[Union[int, float]]) -> Union[int, float]:\n",
      "    \"\"\"Finds the maximum value in the data.\"\"\"\n",
      "    return max(data)\n",
      "\n",
      "def process_data(data: List[Union[int, float]], operation: str) -> Union[int, float]:\n",
      "    \"\"\"Processes the data based on the specified operation.\"\"\"\n",
      "    if operation == 'sum':\n",
      "        return calculate_sum(data)\n",
      "    elif operation == 'average':\n",
      "        return calculate_average(data)\n",
      "    elif operation == 'max':\n",
      "        return find_max(data)\n",
      "    else:\n",
      "        raise ValueError(f\"Unsupported operation: {operation}\")\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to refactor the 'bad_code'.\n",
    "refactor_prompt = f\"\"\"\n",
    "Act as a senior Python developer. Improve the following code by refactoring it to break single function\n",
    "into smaller, more manageable functions. Additionally, ensure that the code adheres to best practices,\n",
    "uses built-in Python functions where applicable, and is more readable. Add type hints and return types to the function signatures.\n",
    "\n",
    "```python\n",
    "{bad_code}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Refactoring Code ---\")\n",
    "refactored_code = get_completion(refactor_prompt, client, model_name, api_provider)\n",
    "cleaned_code = clean_llm_output(refactored_code, language='python')\n",
    "print(cleaned_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Docstrings\n",
    "\n",
    "**Task:** Prompt the LLM to generate high-quality docstrings for the newly refactored code.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a new prompt.\n",
    "2.  Provide the `refactored_code` from the previous step as context.\n",
    "3.  Instruct the LLM to generate Google-style Python docstrings for each function.\n",
    "4.  The docstrings should include a description of the function, its arguments (`Args:`), and what it returns (`Returns:`).\n",
    "\n",
    "**Expected Quality:** The refactored Python code, now with complete and professional-looking docstrings for each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Docstrings ---\n",
      "from typing import List, Union\n",
      "\n",
      "def calculate_sum(data: List[Union[int, float]]) -> Union[int, float]:\n",
      "    \"\"\"Calculates the sum of the data.\n",
      "\n",
      "    Args:\n",
      "        data (List[Union[int, float]]): A list of numerical values (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        Union[int, float]: The sum of the provided data.\n",
      "    \"\"\"\n",
      "    return sum(data)\n",
      "\n",
      "def calculate_average(data: List[Union[int, float]]) -> float:\n",
      "    \"\"\"Calculates the average of the data.\n",
      "\n",
      "    Args:\n",
      "        data (List[Union[int, float]]): A list of numerical values (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        float: The average of the provided data.\n",
      "    \"\"\"\n",
      "    return sum(data) / len(data)\n",
      "\n",
      "def find_max(data: List[Union[int, float]]) -> Union[int, float]:\n",
      "    \"\"\"Finds the maximum value in the data.\n",
      "\n",
      "    Args:\n",
      "        data (List[Union[int, float]]): A list of numerical values (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        Union[int, float]: The maximum value in the provided data.\n",
      "    \"\"\"\n",
      "    return max(data)\n",
      "\n",
      "def process_data(data: List[Union[int, float]], operation: str) -> Union[int, float]:\n",
      "    \"\"\"Processes the data based on the specified operation.\n",
      "\n",
      "    Args:\n",
      "        data (List[Union[int, float]]): A list of numerical values (integers or floats).\n",
      "        operation (str): The operation to perform on the data. Supported operations are 'sum', 'average', and 'max'.\n",
      "\n",
      "    Returns:\n",
      "        Union[int, float]: The result of the operation performed on the data.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If the specified operation is unsupported.\n",
      "    \"\"\"\n",
      "    if operation == 'sum':\n",
      "        return calculate_sum(data)\n",
      "    elif operation == 'average':\n",
      "        return calculate_average(data)\n",
      "    elif operation == 'max':\n",
      "        return find_max(data)\n",
      "    else:\n",
      "        raise ValueError(f\"Unsupported operation: {operation}\")\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to add Google-style docstrings to the refactored code.\n",
    "docstring_prompt = f\"\"\"\n",
    "Act as a senior Python developer. Add Google-style docstrings to the following refactored code.\n",
    "```python\n",
    "{refactored_code}\n",
    "```\n",
    "Ensure that the docstrings are clear, concise, and provide descriptions about the function's purpose, parameters, and return values.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Docstrings ---\")\n",
    "code_with_docstrings = get_completion(docstring_prompt, client, model_name, api_provider)\n",
    "cleaned_code_with_docstrings = clean_llm_output(code_with_docstrings, language='python')\n",
    "print(cleaned_code_with_docstrings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Generating a Project README\n",
    "\n",
    "**Task:** Generate a comprehensive `README.md` file for the entire Onboarding Tool project.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a final prompt that instructs the LLM to act as a technical writer.\n",
    "2.  This time, you will provide multiple pieces of context: the `day1_prd.md` and the `app/main.py` source code. (You will need to load these files).\n",
    "3.  Ask the LLM to generate a `README.md` file with the following sections:\n",
    "    * Project Title\n",
    "    * Overview (based on the PRD)\n",
    "    * Features\n",
    "    * API Endpoints (with `curl` examples)\n",
    "    * Setup and Installation instructions.\n",
    "4.  Save the final output to `README.md` in the project's root directory.\n",
    "\n",
    "**Expected Quality:** A complete, professional `README.md` file that provides a comprehensive overview of the project for other developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Project README ---\n",
      "# Product Requirements Document: Example Product\n",
      "\n",
      "## Overview\n",
      "\n",
      "This project aims to create a comprehensive onboarding platform that streamlines the onboarding process for new hires. Our platform provides a centralized, user-friendly interface designed to improve productivity and engagement by minimizing the friction typically associated with onboarding. \n",
      "\n",
      "### Vision\n",
      "To enhance productivity and engagement for new hires by reducing onboarding friction.\n",
      "\n",
      "### Problem Statement\n",
      "New hires currently face a fragmented and overwhelming onboarding experience, which leads to confusion and inefficiency.\n",
      "\n",
      "### Key Goals\n",
      "1. **Improve New Hire Efficiency**: Reduce the time-to-first-contribution by 20% in Q1.\n",
      "2. **Reduce Support Load**: Decrease repetitive questions to HR by 30%.\n",
      "3. **Increase Engagement**: Achieve a 95% onboarding completion rate.\n",
      "\n",
      "## Features\n",
      "\n",
      "- **User Authentication**: Secure login via company credentials.\n",
      "- **Task Checklist**: Personalized onboarding tasks for new hires.\n",
      "- **Document Repository**: Centralized access to onboarding documents.\n",
      "- **Mentorship Connection**: Facilitate mentorship between new hires and team members.\n",
      "- **Team Introduction**: Features to help new hires get acquainted with their teams.\n",
      "- **Social Engagement and Gamification**: Engaging features to promote team interaction.\n",
      "\n",
      "## FastAPI Endpoints\n",
      "\n",
      "### Create a User\n",
      "\n",
      "- **Endpoint**: `/users/`\n",
      "- **Method**: `POST`\n",
      "- **Description**: Create a new user in the platform.\n",
      "- **Request Body**:\n",
      "  ```json\n",
      "  {\n",
      "    \"name\": \"John Doe\",\n",
      "    \"email\": \"john.doe@example.com\",\n",
      "    \"role\": \"New Hire\"\n",
      "  }\n",
      "  ```\n",
      "- **Curl Example**:\n",
      "  ```bash\n",
      "  curl -X POST \"http://127.0.0.1:8000/users/\" -H \"Content-Type: application/json\" -d '{\"name\": \"John Doe\", \"email\": \"john.doe@example.com\", \"role\": \"New Hire\"}'\n",
      "  ```\n",
      "\n",
      "### List All Users\n",
      "\n",
      "- **Endpoint**: `/users/`\n",
      "- **Method**: `GET`\n",
      "- **Description**: Retrieve a list of all users.\n",
      "- **Query Parameters**:\n",
      "  - `skip` (optional): Number of records to skip.\n",
      "  - `limit` (optional): Maximum number of records to return.\n",
      "- **Curl Example**:\n",
      "  ```bash\n",
      "  curl -X GET \"http://127.0.0.1:8000/users/\"\n",
      "  ```\n",
      "\n",
      "### Get User by ID\n",
      "\n",
      "- **Endpoint**: `/users/{user_id}`\n",
      "- **Method**: `GET`\n",
      "- **Description**: Retrieve a user by their unique ID.\n",
      "- **Curl Example**:\n",
      "  ```bash\n",
      "  curl -X GET \"http://127.0.0.1:8000/users/1\"\n",
      "  ```\n",
      "\n",
      "## Setup and Installation\n",
      "\n",
      "### Prerequisites\n",
      "\n",
      "- Python 3.8 or higher\n",
      "- SQLite\n",
      "\n",
      "### Installation Steps\n",
      "\n",
      "1. **Clone the Repository**:\n",
      "   ```bash\n",
      "   git clone https://github.com/yourusername/onboarding-platform.git\n",
      "   cd onboarding-platform\n",
      "   ```\n",
      "\n",
      "2. **Create a Virtual Environment**:\n",
      "   ```bash\n",
      "   python -m venv venv\n",
      "   source venv/bin/activate  # On Windows use `venv\\Scripts\\activate`\n",
      "   ```\n",
      "\n",
      "3. **Install Dependencies**:\n",
      "   ```bash\n",
      "   pip install -r requirements.txt\n",
      "   ```\n",
      "\n",
      "4. **Set Up the Database**:\n",
      "   - The database will be automatically initialized when running the application for the first time.\n",
      "\n",
      "5. **Run the Application**:\n",
      "   ```bash\n",
      "   uvicorn main:app --reload\n",
      "   ```\n",
      "\n",
      "6. **Access the API**:\n",
      "   - Open your browser and navigate to `http://127.0.0.1:8000/docs` to access the API documentation.\n",
      "\n",
      "### Notes\n",
      "\n",
      "- Ensure you have the necessary permissions to create and manage SQLite databases on your system.\n",
      "- The `requirements.txt` file should list all necessary Python packages, such as FastAPI, SQLAlchemy, and Pydantic.\n",
      "✅ Successfully saved artifact to: README.md\n"
     ]
    }
   ],
   "source": [
    "# Load the necessary context files\n",
    "prd_content = load_artifact(\"artifacts/day1_prd.md\")\n",
    "api_code = load_artifact(\"app/main.py\")\n",
    "\n",
    "# TODO: Write a prompt to generate a complete README.md file.\n",
    "readme_prompt = f\"\"\"Act as a technical writer. Generate a comprehensive README.md file for the project based on the following PRD and API code.\n",
    "\n",
    "PRD:\n",
    "{prd_content}\n",
    "\n",
    "API code:\n",
    "{api_code}\n",
    "\n",
    "The README.md should include the following sections:\n",
    "- Project Title\n",
    "- Overview (based on the PRD)\n",
    "- Features\n",
    "- FastAPI Endpoints (with curl examples) http://127.0.0.1:8000\n",
    "- Setup and Installation instructions\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Project README ---\")\n",
    "if prd_content and api_code:\n",
    "    readme_content = get_completion(readme_prompt, client, model_name, api_provider)\n",
    "    cleaned_readme = clean_llm_output(readme_content, language='markdown')\n",
    "    print(cleaned_readme)\n",
    "    save_artifact(cleaned_readme, \"README.md\")\n",
    "else:\n",
    "    print(\"Skipping README generation because PRD or API code is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to perform two of the most valuable code quality tasks: refactoring and documentation. You've seen how AI can help transform messy code into a clean, maintainable structure and how it can generate comprehensive documentation from high-level project artifacts and source code. These skills are a massive productivity multiplier for any development team.\n",
    "\n",
    "> **Key Takeaway:** LLMs excel at understanding and generating structured text, whether that structure is code or documentation. Providing a clear 'before' state (the bad code) and a clear goal (the refactoring principles) allows the AI to perform complex code transformation and documentation tasks efficiently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
