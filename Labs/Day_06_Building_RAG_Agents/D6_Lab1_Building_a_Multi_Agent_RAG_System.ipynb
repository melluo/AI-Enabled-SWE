{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 6 - Lab 1: Building a Multi-Agent RAG System\n",
        "\n",
        "**Objective:** Build a RAG (Retrieval-Augmented Generation) system orchestrated by LangGraph, scaling in complexity from a single agent to a multi-agent team that can reason about a knowledge base.\n",
        "\n",
        "**Estimated Time:** 135 minutes\n",
        "\n",
        "**Introduction:**\n",
        "Welcome to Day 6! Today, we build one of the most powerful and common patterns for enterprise AI: a system that can answer questions about your private documents. We will use LangGraph to create a 'research team' of AI agents. Each agent will have a specific job, and LangGraph will act as the manager, orchestrating their collaboration to find the best possible answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup\n",
        "\n",
        "We need several libraries for this lab. `langgraph` is the core orchestrator, `langchain` provides the building blocks, `faiss-cpu` is for our vector store, and `pypdf` is for loading documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the project's root directory to the Python path\n",
        "try:\n",
        "    # This works when running as a script\n",
        "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))\n",
        "except NameError:\n",
        "    # This works when running in an interactive environment (like a notebook)\n",
        "    # We go up two levels from the notebook's directory to the project root.\n",
        "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This helper will install packages if they are not found\n",
        "import importlib\n",
        "def install_if_missing(package):\n",
        "    try:\n",
        "        importlib.import_module(package)\n",
        "    except ImportError:\n",
        "        print(f\"{package} not found, installing...\")\n",
        "        %pip install -q {package}\n",
        "\n",
        "install_if_missing('langgraph')\n",
        "install_if_missing('langchain')\n",
        "install_if_missing('langchain_community')\n",
        "install_if_missing('langchain_openai')\n",
        "install_if_missing('faiss-cpu')\n",
        "install_if_missing('pypdf')\n",
        "\n",
        "import os\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from utils import setup_llm_client, load_artifact\n",
        "\n",
        "client, model_name, api_provider = setup_llm_client()\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Building the Knowledge Base\n",
        "\n",
        "An agent is only as smart as the information it can access. We will create a vector store containing all the project artifacts we've created so far. This will be our agent's 'knowledge base'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_knowledge_base():\n",
        "    \"\"\"Loads all artifacts and creates a FAISS vector store.\"\"\"\n",
        "    artifact_paths = [\n",
        "        \"artifacts/prd.md\",\n",
        "        \"artifacts/schema.sql\",\n",
        "        \"artifacts/adr_001_framework_choice.md\"\n",
        "    ]\n",
        "    all_docs = []\n",
        "    for path in artifact_paths:\n",
        "        if os.path.exists(path):\n",
        "            # For simplicity, we'll treat each file as a single document.\n",
        "            # A more advanced loader could handle different file types.\n",
        "            content = load_artifact(path)\n",
        "            from langchain_core.documents import Document\n",
        "            all_docs.append(Document(page_content=content, metadata={\"source\": path}))\n",
        "        else:\n",
        "            print(f\"Warning: Artifact not found at {path}\")\n",
        "\n",
        "    if not all_docs:\n",
        "        print(\"No documents found to create knowledge base.\")\n",
        "        return None\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    splits = text_splitter.split_documents(all_docs)\n",
        "    \n",
        "    print(f\"Creating vector store from {len(splits)} document splits...\")\n",
        "    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
        "    return vectorstore.as_retriever()\n",
        "\n",
        "retriever = create_knowledge_base()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: The Challenges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 1 (Foundational): A Single-Agent RAG System\n",
        "\n",
        "**Task:** Build a simple LangGraph with two nodes: one to retrieve documents and one to generate an answer.\n",
        "\n",
        "**Instructions:**\n",
        "1.  Define the state for your graph. It should contain keys for `question` and `documents`.\n",
        "2.  Create a \"Retriever Agent\" node. This is a Python function that takes the state, uses the `retriever` to get relevant documents, and updates the state with the results.\n",
        "3.  Create a \"Generate Answer\" node. This function takes the state, creates a prompt with the question and retrieved documents, calls the LLM, and stores the answer.\n",
        "4.  Build the `StatefulGraph`, add the nodes, and define the edges (`RETRIEVE` -> `GENERATE`).\n",
        "5.  Compile the graph and invoke it with a question about your project.\n",
        "\n",
        "**Expected Quality:** A functional graph that can answer a simple question (e.g., \"What is the purpose of this project?\") by retrieving context from the project artifacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Write the code for the single-agent RAG system using LangGraph.\n",
        "# This will involve defining the state, the nodes, and the graph itself.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 2 (Intermediate): A Two-Agent System with a Grader\n",
        "\n",
        "**Task:** Add a second agent to your graph that acts as a \"Grader,\" deciding if the retrieved documents are relevant enough to answer the question.\n",
        "\n",
        "**Instructions:**\n",
        "1.  Keep your `RETRIEVE` node from the previous challenge.\n",
        "2.  Create a new \"Grader Agent\" node. This function takes the state (question and documents) and calls an LLM with a specific prompt: \"Based on the question and the following documents, is the information sufficient to answer the question? Answer with only 'yes' or 'no'.\"\n",
        "3.  Add a **conditional edge** to your graph. After the `RETRIEVE` node, the graph should go to the `GRADE` node. After the `GRADE` node, it should check the grader's response. If 'yes', it proceeds to the `GENERATE` node. If 'no', it goes to an `END` node, concluding that it cannot answer the question.\n",
        "\n",
        "**Expected Quality:** A more robust graph that can gracefully handle cases where its knowledge base doesn't contain the answer, preventing it from hallucinating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Write the code for the two-agent system with a Grader and conditional edges.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 3 (Advanced): A 5-Agent Research Team with Human-in-the-Loop\n",
        "\n",
        "**Task:** Build a sophisticated \"research team\" of specialized agents and add a human validation step before the final answer is given.\n",
        "\n",
        "**Instructions:**\n",
        "1.  **Specialize your retriever:** Create two separate retrievers. One for the PRD (`prd_retriever`) and one for the technical documents (`tech_retriever` for schema and ADRs).\n",
        "2.  **Define the Agents:**\n",
        "    * `ProjectManagerAgent`: The entry point. It uses an LLM to decide whether the user's question is about product requirements or technical details, and routes to the appropriate researcher.\n",
        "    * `PRDResearcherAgent`: A node that uses the `prd_retriever`.\n",
        "    * `TechResearcherAgent`: A node that uses the `tech_retriever`.\n",
        "    * `SynthesizerAgent`: A node that takes the collected documents from the researchers and synthesizes a draft answer.\n",
        "3.  **Add a Human-in-the-Loop Node:** After the `SYNTHESIZE` node, create a special node that prints the draft answer and the source documents and then waits for user input (e.g., `input('Is this answer helpful? (yes/no): ')`).\n",
        "4.  **Build the Graph:** Use conditional edges to orchestrate the flow: `PM` -> (`PRD_RESEARCHER` or `TECH_RESEARCHER`) -> `SYNTHESIZE` -> `HUMAN_VALIDATION` -> `END`.\n",
        "\n",
        "**Expected Quality:** A highly advanced agentic system that mimics a real-world research workflow, including specialist roles, information synthesis, and final human approval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Write the code for the five-agent research team with specialized retrievers and a human validation step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab Conclusion\n",
        "\n",
        "Incredible work! You have now built a truly sophisticated AI system. You've learned how to create a knowledge base for an agent and how to use LangGraph to orchestrate a team of specialized agents to solve a complex problem. Most importantly, you implemented a human-in-the-loop validation step, which is a critical pattern for building safe, reliable, and trustworthy AI applications. In the next lab, we will integrate this powerful system into our FastAPI backend."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}