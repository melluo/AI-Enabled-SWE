{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 5 - Lab 1: Foundations of AI Agents - Tool-Using Agents\n",
        "\n",
        "**Objective:** Introduce the fundamental concepts of AI agents by building agents that can use external tools to accomplish tasks they cannot perform on their own.\n",
        "\n",
        "**Estimated Time:** 135 minutes\n",
        "\n",
        "**Introduction:**\n",
        "Welcome to Week 2! We are now shifting from using AI to build a traditional application to building applications that *are* AI. An 'agent' is more than just a prompt; it's a system that can reason, plan, and use tools to achieve a goal. In this lab, you will build your first simple agents using both OpenAI's Assistants API and the flexible LangChain framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup\n",
        "\n",
        "We will set up our environment, which for today includes installing the `langchain`, `langchain-community`, and `tavily-python` libraries. Tavily is a search engine API optimized for AI agents, which we will use as our first tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the project's root directory to the Python path\n",
        "try:\n",
        "    # This works when running as a script\n",
        "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))\n",
        "except NameError:\n",
        "    # This works when running in an interactive environment (like a notebook)\n",
        "    # We go up two levels from the notebook's directory to the project root.\n",
        "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This helper will install packages if they are not found\n",
        "import importlib\n",
        "def install_if_missing(package):\n",
        "    try:\n",
        "        importlib.import_module(package)\n",
        "    except ImportError:\n",
        "        print(f\"{package} not found, installing...\")\n",
        "        %pip install -q {package}\n",
        "\n",
        "install_if_missing('langchain')\n",
        "install_if_missing('langchain_community')\n",
        "install_if_missing('langchain_openai')\n",
        "install_if_missing('tavily-python')\n",
        "\n",
        "from utils import setup_llm_client\n",
        "client, model_name, api_provider = setup_llm_client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: The Challenges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 1 (Foundational): Using the OpenAI Assistants API\n",
        "\n",
        "**Task:** Use the OpenAI Assistants API to create a simple, stateful assistant with a built-in tool (the Code Interpreter).\n",
        "\n",
        "**Instructions:**\n",
        "1.  Use the `client.beta.assistants.create` method to define a new assistant. Give it a name and instructions to act as a helpful math tutor.\n",
        "2.  Enable the `code_interpreter` tool in the assistant's definition.\n",
        "3.  Create a new `thread` for the conversation.\n",
        "4.  Add a `message` to the thread asking a math question that requires calculation, like \"What is `(123 * 4) + (567 / 8)`?\".\n",
        "5.  Create a `run` to process the message and wait for it to complete.\n",
        "6.  Retrieve and print the messages from the thread to see the assistant's response.\n",
        "\n",
        "**Expected Quality:** A successful interaction with the OpenAI Assistant, where it uses its Code Interpreter tool to solve the math problem and provide the correct answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from openai import OpenAI\n",
        "\n",
        "# Ensure you are using the OpenAI client for this challenge\n",
        "if api_provider != 'openai':\n",
        "    print(\"This challenge requires an OpenAI client. Please set up your client accordingly.\")\n",
        "else:\n",
        "    # TODO: 1. Create an assistant\n",
        "    # Give it instructions to be a math tutor and enable the code interpreter tool.\n",
        "    assistant = None # Your assistant creation code here\n",
        "    print(f\"Assistant created with ID: {assistant.id}\")\n",
        "\n",
        "    # TODO: 2. Create a thread\n",
        "    thread = None # Your thread creation code here\n",
        "    print(f\"Thread created with ID: {thread.id}\")\n",
        "\n",
        "    # TODO: 3. Add a message to the thread\n",
        "    message = None # Your message creation code here\n",
        "\n",
        "    # TODO: 4. Create a run and wait for completion\n",
        "    run = None # Your run creation code here\n",
        "    \n",
        "    # Polling for completion\n",
        "    while run.status != 'completed':\n",
        "        time.sleep(1)\n",
        "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "        print(f\"Run status: {run.status}\")\n",
        "\n",
        "    # TODO: 5. Retrieve and print the messages\n",
        "    messages = None # Your message retrieval code here\n",
        "    for msg in messages.data:\n",
        "        print(f\"\\n{msg.role.capitalize()}: {msg.content[0].text.value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 2 (Intermediate): Building a LangChain Agent with One Tool\n",
        "\n",
        "**Task:** Build a simple LangChain agent that can use the Tavily Search API to answer questions about current events.\n",
        "\n",
        "**Instructions:**\n",
        "1.  Import `TavilySearchResults` from `langchain_community.tools.tavily_search`.\n",
        "2.  Import `create_tool_calling_agent` and `AgentExecutor` from `langchain.agents`.\n",
        "3.  Import `ChatPromptTemplate` from `langchain_core.prompts`.\n",
        "4.  Instantiate the `TavilySearchResults` tool.\n",
        "5.  Create a prompt template. It must include a placeholder for `agent_scratchpad`, which is where the agent keeps its internal thoughts.\n",
        "6.  Create the agent by passing the LLM, the list of tools, and the prompt to `create_tool_calling_agent`.\n",
        "7.  Create an `AgentExecutor` to run the agent.\n",
        "8.  Invoke the agent with a question that requires a web search, like \"What was the score of the last Super Bowl?\"\n",
        "\n",
        "**Expected Quality:** The agent should successfully use the Tavily tool to search the web, find the correct information, and provide an accurate answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Perform all necessary imports\n",
        "\n",
        "# TODO: 1. Instantiate the Tavily search tool\n",
        "search_tool = None # Your code here\n",
        "tools = [search_tool]\n",
        "\n",
        "# TODO: 2. Create the prompt template\n",
        "# Make sure to include placeholders for 'input' and 'agent_scratchpad'\n",
        "prompt = None # Your prompt template here\n",
        "\n",
        "# TODO: 3. Create the agent\n",
        "agent = None # Your agent creation code here\n",
        "\n",
        "# TODO: 4. Create the AgentExecutor\n",
        "agent_executor = None # Your executor creation code here\n",
        "\n",
        "# TODO: 5. Invoke the agent with a question\n",
        "question = \"What was the score of the last Super Bowl?\"\n",
        "result = None # Your invocation code here\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 3 (Advanced): Building a Multi-Tool Agent\n",
        "\n",
        "**Task:** Create a more advanced LangChain agent that has access to *multiple* tools and must reason about which one to use for a given task.\n",
        "\n",
        "**Instructions:**\n",
        "1.  Keep the `TavilySearchResults` tool from the previous challenge.\n",
        "2.  Define a new, custom tool for a calculator. You can do this by creating a simple Python function (e.g., `def multiply(a: int, b: int) -> int:`) and then decorating it with the `@tool` decorator from `langchain_core.tools`.\n",
        "3.  Create a new list of tools that includes both the search tool and your new calculator tool.\n",
        "4.  Create a new agent and `AgentExecutor` using this expanded list of tools.\n",
        "5.  Invoke the agent twice with different questions:\n",
        "    * A question that requires the calculator tool (e.g., \"What is 25 * 48?\").\n",
        "    * A question that requires the search tool (e.g., \"Who is the current CEO of Apple?\").\n",
        "6.  Observe how the agent correctly chooses which tool to use for each question.\n",
        "\n",
        "**Expected Quality:** A single agent that can dynamically decide which tool to use based on the user's query, demonstrating the core reasoning capability of an agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "# TODO: 1. Define your custom calculator tool\n",
        "# Use the @tool decorator\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiplies two integers together.\"\"\"\n",
        "    # Your implementation here\n",
        "    return 0\n",
        "\n",
        "# TODO: 2. Create the new list of tools\n",
        "multi_tool_list = [] # Your list here\n",
        "\n",
        "# TODO: 3. Create the new multi-tool agent and executor\n",
        "# The prompt and creation process are the same as before, just with the new tool list.\n",
        "multi_tool_agent = None # Your agent creation code here\n",
        "multi_tool_executor = None # Your executor creation code here\n",
        "\n",
        "# TODO: 4. Invoke the agent with a math question\n",
        "math_question = \"What is 25 * 48?\"\n",
        "math_result = None # Your invocation code here\n",
        "print(f\"Query: {math_question}\\nResult: {math_result}\\n\")\n",
        "\n",
        "# TODO: 5. Invoke the agent with a search question\n",
        "search_question = \"Who is the current CEO of Apple?\"\n",
        "search_result = None # Your invocation code here\n",
        "print(f\"Query: {search_question}\\nResult: {search_result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab Conclusion\n",
        "\n",
        "Congratulations! You have successfully built your first AI agents. You started with the high-level OpenAI Assistants API and then moved to the more flexible LangChain framework. You've learned how to give agents tools to extend their capabilities and, most importantly, how to build an agent that can reason about which tool to use for a specific task. This is the foundational skill for all advanced agentic workflows we will explore in the coming days."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}